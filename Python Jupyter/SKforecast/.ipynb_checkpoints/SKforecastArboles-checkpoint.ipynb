{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51e002ea",
   "metadata": {},
   "source": [
    "Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0d60b0-7da4-4b74-9718-e9d8f56baf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install skforecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28aa8df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergiocalderon/anaconda3/envs/Ambiente39/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Data manipulation\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plots\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['lines.linewidth'] = 1.5\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Modeling and Forecasting\n",
    "# ==============================================================================\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\n",
    "from skforecast.ForecasterAutoregDirect import ForecasterAutoregDirect\n",
    "from skforecast.model_selection import grid_search_forecaster\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "from skforecast.utils import save_forecaster\n",
    "from skforecast.utils import load_forecaster\n",
    "\n",
    "# Warnings configuration\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f749150",
   "metadata": {},
   "source": [
    "Para mas información visitar https://cienciadedatos.net/documentos/py27-forecasting-series-temporales-python-scikitlearn.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c2cc0b",
   "metadata": {},
   "source": [
    "Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453005a6",
   "metadata": {},
   "source": [
    "Vamos a trabajar con los datos de precipitación mensual ponderada de Colombia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a61db53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yprecip</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fecha</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-01</th>\n",
       "      <td>3.758065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-02-01</th>\n",
       "      <td>4.235714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-03-01</th>\n",
       "      <td>4.764516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-01</th>\n",
       "      <td>5.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-01</th>\n",
       "      <td>4.438710</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             yprecip\n",
       "Fecha               \n",
       "2009-01-01  3.758065\n",
       "2009-02-01  4.235714\n",
       "2009-03-01  4.764516\n",
       "2009-04-01  5.400000\n",
       "2009-05-01  4.438710"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lluvia=pd.read_excel('Lluvia.xlsx')\n",
    "Lluvia=Lluvia.set_index('Fecha')\n",
    "Lluvia=Lluvia.asfreq('MS')\n",
    "Lluvia=Lluvia.rename(columns={'lluvia':'yprecip'})\n",
    "Lluvia.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c6694ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de filas con valores faltantes: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(f'Numero de filas con valores faltantes: {Lluvia.isnull().any(axis=1).mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4043b58",
   "metadata": {},
   "source": [
    "Verificación de que la serie es regularmente espaciada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60d6e096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Lluvia.index == pd.date_range(start=Lluvia.index.min(),\n",
    "                             end=Lluvia.index.max(),\n",
    "                             freq=Lluvia.index.freq)).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebb65281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(132, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lluvia.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d59c94",
   "metadata": {},
   "source": [
    "Vamos a establecer que los últimos 12 meses(periodos) sean usando para medir la capacida predictiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9795da1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dates : 2009-01-01 00:00:00 --- 2018-12-01 00:00:00  (n=120)\n",
      "Test dates  : 2019-01-01 00:00:00 --- 2019-12-01 00:00:00  (n=12)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x180 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "steps = 12\n",
    "data_train = Lluvia[:-steps]\n",
    "data_test  = Lluvia[-steps:]\n",
    "\n",
    "print(f\"Train dates : {data_train.index.min()} --- {data_train.index.max()}  (n={len(data_train)})\")\n",
    "print(f\"Test dates  : {data_test.index.min()} --- {data_test.index.max()}  (n={len(data_test)})\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7, 2.5))\n",
    "data_train['yprecip'].plot(ax=ax, label='train')\n",
    "data_test['yprecip'].plot(ax=ax, label='test')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49fcf0f",
   "metadata": {},
   "source": [
    "Vamos a crear un modelos a través de la clase ForecasterAutoreg, el cual es entrenado usando DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e7a45e",
   "metadata": {},
   "source": [
    "# Clase ForecasterAutoreg \n",
    "\n",
    "Permite crear una ventana de 12 retardos, es decir, se tomarán los últimos doce meses como predictores.Note que acá no se optimiza el número de nodos o particiones. Tenga en cuenta que se usarán las predicciones que se van obteniendo para predecir los pasos adelante que siguen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec2581b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "================= \n",
       "ForecasterAutoreg \n",
       "================= \n",
       "Regressor: DecisionTreeRegressor() \n",
       "Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
       "Transformer for y: None \n",
       "Transformer for exog: None \n",
       "Window size: 12 \n",
       "Weight function included: False \n",
       "Exogenous included: False \n",
       "Type of exogenous variable: None \n",
       "Exogenous variables names: None \n",
       "Training range: [Timestamp('2009-01-01 00:00:00'), Timestamp('2018-12-01 00:00:00')] \n",
       "Training index type: DatetimeIndex \n",
       "Training index frequency: MS \n",
       "Regressor parameters: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'} \n",
       "fit_kwargs: {} \n",
       "Creation date: 2023-09-23 16:04:57 \n",
       "Last fit date: 2023-09-23 16:04:57 \n",
       "Skforecast version: 0.8.0 \n",
       "Python version: 3.8.8 \n",
       "Forecaster id: None "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train forecaster\n",
    "# ==============================================================================\n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = DecisionTreeRegressor(random_state= 0),\n",
    "                lags      = 12\n",
    "             )\n",
    "\n",
    "forecaster.fit(y=data_train['yprecip'])\n",
    "forecaster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbfc16c",
   "metadata": {},
   "source": [
    "# Predicciones\n",
    " Una vez ajustado el modelo, se procede a hacer la prediccion de los 12 periodos en el fututo adelante, por supuesto usando las predicciones de forma recurrente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27d09e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019-01-01    5.209677\n",
       "2019-02-01    3.864516\n",
       "2019-03-01    2.003571\n",
       "2019-04-01    7.066667\n",
       "2019-05-01    6.846667\n",
       "Freq: MS, Name: pred, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predictions\n",
    "# ==============================================================================\n",
    "steps = 12\n",
    "predictions = forecaster.predict(steps=steps)\n",
    "predictions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c9540a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x180 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "# ==============================================================================\n",
    "fig, ax = plt.subplots(figsize=(7, 2.5))\n",
    "data_train['yprecip'].plot(ax=ax, label='train')\n",
    "data_test['yprecip'].plot(ax=ax, label='test')\n",
    "predictions.plot(ax=ax, label='predictions')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbb95de",
   "metadata": {},
   "source": [
    "# Error de predicción en el conjunto de prueba\n",
    "\n",
    "Acá se usará el conjunto de prueba para cuantificar la capacidad predictiva. Note que esta no es la verdadera capacidad predictiva, Por qué?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53112399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error (mse): 2.2074918034046003\n"
     ]
    }
   ],
   "source": [
    "# Test error\n",
    "# ==============================================================================\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = data_test['yprecip'],\n",
    "                y_pred = predictions\n",
    "            )\n",
    "\n",
    "print(f\"Test error (mse): {error_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ebfab4",
   "metadata": {},
   "source": [
    "# Busqueda de los mejores hiperparámetros\n",
    "\n",
    "La idea ahora es buscar la mejor combinación de retardos e hiperparámetros del modelo de árboles por medio de la función grid_search_forecaster. También hace random search y Bayesian search. Se hace Backtesting para validar la capacidad predictiva que tienen los modelos bajo los hiperparámetros propuestos. Se puede hacer validación cruzada o la tradicional entrenamiento y prueba. En este ejemplo se hace validación cruzada secuencial. Vale la pena recordar que validación cruzada se hace sobre el mismo conjunto de entrenamiento, lo cual es diferente al caso de tener un conjunto de validación. Pero en el caso de tener conjunto de validación se debe tener en cuenta, por favor chequear https://skforecast.org/0.4.3/notebooks/prediction-intervals.html y debe incorporarse el conjunto de validación al de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d21a857c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 60.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lags grid:   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "params grid:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\n",
      "params grid:  30%|███       | 3/10 [00:00<00:00, 28.69it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  60%|██████    | 6/10 [00:00<00:00, 28.02it/s]\u001b[A\n",
      "params grid:  90%|█████████ | 9/10 [00:00<00:00, 27.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "lags grid:  17%|█▋        | 1/6 [00:00<00:01,  2.72it/s]   \u001b[A\n",
      "params grid:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  30%|███       | 3/10 [00:00<00:00, 29.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  60%|██████    | 6/10 [00:00<00:00, 29.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  90%|█████████ | 9/10 [00:00<00:00, 28.89it/s]\u001b[A\n",
      "lags grid:  33%|███▎      | 2/6 [00:00<00:01,  2.80it/s]   \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  40%|████      | 4/10 [00:00<00:00, 31.18it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  80%|████████  | 8/10 [00:00<00:00, 28.95it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "lags grid:  50%|█████     | 3/6 [00:01<00:01,  2.84it/s]   \u001b[A\n",
      "params grid:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  40%|████      | 4/10 [00:00<00:00, 30.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  80%|████████  | 8/10 [00:00<00:00, 28.63it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "lags grid:  67%|██████▋   | 4/6 [00:01<00:00,  2.83it/s]   \u001b[A\n",
      "params grid:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  40%|████      | 4/10 [00:00<00:00, 30.78it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  80%|████████  | 8/10 [00:00<00:00, 28.61it/s]\u001b[A\n",
      "lags grid:  83%|████████▎ | 5/6 [00:01<00:00,  2.83it/s]   \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  30%|███       | 3/10 [00:00<00:00, 29.40it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  60%|██████    | 6/10 [00:00<00:00, 27.14it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  90%|█████████ | 9/10 [00:00<00:00, 27.19it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "lags grid: 100%|██████████| 6/6 [00:02<00:00,  2.80it/s]   \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10] \n",
      "  Parameters: {'max_depth': 10}\n",
      "  Backtesting metric: 1.5625980129565606\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Grid search\n",
    "# ==============================================================================\n",
    "steps = 12\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = DecisionTreeRegressor(random_state= 0),\n",
    "                lags      = 2 # This value will be replaced in the grid search\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3,5,10,12,15, 20]\n",
    "\n",
    "# Regressor's hyperparameters\n",
    "param_grid = { 'max_depth': [1,2,3,4,5,6,7,8,9,10]}\n",
    "\n",
    "results_grid = grid_search_forecaster(\n",
    "                        forecaster         = forecaster,\n",
    "                        y                  = data_train['yprecip'],\n",
    "                        param_grid         = param_grid,\n",
    "                        lags_grid          = lags_grid,\n",
    "                        steps              = steps,\n",
    "                        refit              = True,\n",
    "                        metric             = 'mean_squared_error',\n",
    "                        initial_train_size = int(len(data_train)*0.5),\n",
    "                        fixed_train_size   = False,\n",
    "                        return_best        = True,\n",
    "                        verbose            = True\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28fa8435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>max_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>1.562598</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 8}</td>\n",
       "      <td>1.863724</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 7}</td>\n",
       "      <td>1.881522</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>1.951654</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>{'max_depth': 4}</td>\n",
       "      <td>2.067690</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>{'max_depth': 1}</td>\n",
       "      <td>2.069260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 9}</td>\n",
       "      <td>2.102679</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.152084</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 4}</td>\n",
       "      <td>2.293611</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>{'max_depth': 3}</td>\n",
       "      <td>2.305430</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.310307</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'max_depth': 1}</td>\n",
       "      <td>2.452132</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'max_depth': 1}</td>\n",
       "      <td>2.493161</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 3}</td>\n",
       "      <td>2.505318</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>2.511875</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>2.516893</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.518560</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'max_depth': 3}</td>\n",
       "      <td>2.604460</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'max_depth': 4}</td>\n",
       "      <td>2.609743</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.670927</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 4}</td>\n",
       "      <td>2.704901</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>{'max_depth': 7}</td>\n",
       "      <td>2.726530</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'max_depth': 7}</td>\n",
       "      <td>2.756749</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>2.763431</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>{'max_depth': 6}</td>\n",
       "      <td>2.765719</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 6}</td>\n",
       "      <td>2.845201</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 7}</td>\n",
       "      <td>2.857206</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>2.860514</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>{'max_depth': 8}</td>\n",
       "      <td>2.882728</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'max_depth': 8}</td>\n",
       "      <td>2.905239</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'max_depth': 6}</td>\n",
       "      <td>2.928603</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'max_depth': 3}</td>\n",
       "      <td>2.938157</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>2.999903</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 3}</td>\n",
       "      <td>3.016890</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>{'max_depth': 9}</td>\n",
       "      <td>3.021739</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>3.036018</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 7}</td>\n",
       "      <td>3.203887</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>3.262575</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 6}</td>\n",
       "      <td>3.269777</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'max_depth': 9}</td>\n",
       "      <td>3.317327</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>3.354087</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 8}</td>\n",
       "      <td>3.579458</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 3}</td>\n",
       "      <td>3.636224</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 9}</td>\n",
       "      <td>3.643598</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 1}</td>\n",
       "      <td>3.701347</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 1}</td>\n",
       "      <td>3.703238</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 8}</td>\n",
       "      <td>3.784283</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'max_depth': 6}</td>\n",
       "      <td>3.811364</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 4}</td>\n",
       "      <td>3.845076</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 1}</td>\n",
       "      <td>3.985279</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'max_depth': 8}</td>\n",
       "      <td>4.016361</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 9}</td>\n",
       "      <td>4.149539</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'max_depth': 4}</td>\n",
       "      <td>4.150164</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>4.412427</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>4.435413</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'max_depth': 7}</td>\n",
       "      <td>4.554394</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...</td>\n",
       "      <td>{'max_depth': 9}</td>\n",
       "      <td>4.601114</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "      <td>{'max_depth': 10}</td>\n",
       "      <td>4.984825</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>5.002918</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[1, 2, 3, 4, 5]</td>\n",
       "      <td>{'max_depth': 6}</td>\n",
       "      <td>6.419250</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 lags             params  \\\n",
       "29                    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  {'max_depth': 10}   \n",
       "27                    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   {'max_depth': 8}   \n",
       "26                    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   {'max_depth': 7}   \n",
       "31            [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]   {'max_depth': 2}   \n",
       "33            [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]   {'max_depth': 4}   \n",
       "30            [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]   {'max_depth': 1}   \n",
       "28                    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   {'max_depth': 9}   \n",
       "11                                    [1, 2, 3, 4, 5]   {'max_depth': 2}   \n",
       "23                    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   {'max_depth': 4}   \n",
       "32            [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]   {'max_depth': 3}   \n",
       "21                    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   {'max_depth': 2}   \n",
       "50  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   {'max_depth': 1}   \n",
       "40  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   {'max_depth': 1}   \n",
       "2                                           [1, 2, 3]   {'max_depth': 3}   \n",
       "34            [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]   {'max_depth': 5}   \n",
       "4                                           [1, 2, 3]   {'max_depth': 5}   \n",
       "41  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   {'max_depth': 2}   \n",
       "42  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   {'max_depth': 3}   \n",
       "43  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   {'max_depth': 4}   \n",
       "51  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   {'max_depth': 2}   \n",
       "3                                           [1, 2, 3]   {'max_depth': 4}   \n",
       "36            [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]   {'max_depth': 7}   \n",
       "46  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   {'max_depth': 7}   \n",
       "39            [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]  {'max_depth': 10}   \n",
       "35            [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]   {'max_depth': 6}   \n",
       "25                    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   {'max_depth': 6}   \n",
       "16                                    [1, 2, 3, 4, 5]   {'max_depth': 7}   \n",
       "1                                           [1, 2, 3]   {'max_depth': 2}   \n",
       "37            [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]   {'max_depth': 8}   \n",
       "47  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   {'max_depth': 8}   \n",
       "45  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   {'max_depth': 6}   \n",
       "52  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   {'max_depth': 3}   \n",
       "24                    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   {'max_depth': 5}   \n",
       "22                    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   {'max_depth': 3}   \n",
       "38            [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]   {'max_depth': 9}   \n",
       "19                                    [1, 2, 3, 4, 5]  {'max_depth': 10}   \n",
       "6                                           [1, 2, 3]   {'max_depth': 7}   \n",
       "49  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...  {'max_depth': 10}   \n",
       "5                                           [1, 2, 3]   {'max_depth': 6}   \n",
       "48  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   {'max_depth': 9}   \n",
       "44  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   {'max_depth': 5}   \n",
       "17                                    [1, 2, 3, 4, 5]   {'max_depth': 8}   \n",
       "12                                    [1, 2, 3, 4, 5]   {'max_depth': 3}   \n",
       "18                                    [1, 2, 3, 4, 5]   {'max_depth': 9}   \n",
       "10                                    [1, 2, 3, 4, 5]   {'max_depth': 1}   \n",
       "0                                           [1, 2, 3]   {'max_depth': 1}   \n",
       "7                                           [1, 2, 3]   {'max_depth': 8}   \n",
       "55  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   {'max_depth': 6}   \n",
       "13                                    [1, 2, 3, 4, 5]   {'max_depth': 4}   \n",
       "20                    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   {'max_depth': 1}   \n",
       "57  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   {'max_depth': 8}   \n",
       "8                                           [1, 2, 3]   {'max_depth': 9}   \n",
       "53  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   {'max_depth': 4}   \n",
       "54  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   {'max_depth': 5}   \n",
       "59  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...  {'max_depth': 10}   \n",
       "56  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   {'max_depth': 7}   \n",
       "58  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14...   {'max_depth': 9}   \n",
       "9                                           [1, 2, 3]  {'max_depth': 10}   \n",
       "14                                    [1, 2, 3, 4, 5]   {'max_depth': 5}   \n",
       "15                                    [1, 2, 3, 4, 5]   {'max_depth': 6}   \n",
       "\n",
       "    mean_squared_error  max_depth  \n",
       "29            1.562598         10  \n",
       "27            1.863724          8  \n",
       "26            1.881522          7  \n",
       "31            1.951654          2  \n",
       "33            2.067690          4  \n",
       "30            2.069260          1  \n",
       "28            2.102679          9  \n",
       "11            2.152084          2  \n",
       "23            2.293611          4  \n",
       "32            2.305430          3  \n",
       "21            2.310307          2  \n",
       "50            2.452132          1  \n",
       "40            2.493161          1  \n",
       "2             2.505318          3  \n",
       "34            2.511875          5  \n",
       "4             2.516893          5  \n",
       "41            2.518560          2  \n",
       "42            2.604460          3  \n",
       "43            2.609743          4  \n",
       "51            2.670927          2  \n",
       "3             2.704901          4  \n",
       "36            2.726530          7  \n",
       "46            2.756749          7  \n",
       "39            2.763431         10  \n",
       "35            2.765719          6  \n",
       "25            2.845201          6  \n",
       "16            2.857206          7  \n",
       "1             2.860514          2  \n",
       "37            2.882728          8  \n",
       "47            2.905239          8  \n",
       "45            2.928603          6  \n",
       "52            2.938157          3  \n",
       "24            2.999903          5  \n",
       "22            3.016890          3  \n",
       "38            3.021739          9  \n",
       "19            3.036018         10  \n",
       "6             3.203887          7  \n",
       "49            3.262575         10  \n",
       "5             3.269777          6  \n",
       "48            3.317327          9  \n",
       "44            3.354087          5  \n",
       "17            3.579458          8  \n",
       "12            3.636224          3  \n",
       "18            3.643598          9  \n",
       "10            3.701347          1  \n",
       "0             3.703238          1  \n",
       "7             3.784283          8  \n",
       "55            3.811364          6  \n",
       "13            3.845076          4  \n",
       "20            3.985279          1  \n",
       "57            4.016361          8  \n",
       "8             4.149539          9  \n",
       "53            4.150164          4  \n",
       "54            4.412427          5  \n",
       "59            4.435413         10  \n",
       "56            4.554394          7  \n",
       "58            4.601114          9  \n",
       "9             4.984825         10  \n",
       "14            5.002918          5  \n",
       "15            6.419250          6  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search results\n",
    "# ==============================================================================\n",
    "results_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c7978b",
   "metadata": {},
   "source": [
    "# Modelo final\n",
    "\n",
    "En la búsqueda hecha anteriormente se encontró la combinación óptima de los hiperparámetros por medio de validación cruzada secuencial para la predicción 12 pasos adelante por ejemplo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e71002b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train forecaster with the best hyperparameters\n",
    "# ==============================================================================\n",
    "regressor = DecisionTreeRegressor(max_depth=6)\n",
    "                \n",
    "\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = regressor,\n",
    "                lags      = 10\n",
    "             )\n",
    "\n",
    "forecaster.fit(y=data_train['yprecip'])\n",
    "\n",
    "Final_Forecaster=forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bcdf1076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "# ==============================================================================\n",
    "predictions = forecaster.predict(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd207480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x180 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "# ==============================================================================\n",
    "fig, ax = plt.subplots(figsize=(7, 2.5))\n",
    "data_train['yprecip'].plot(ax=ax, label='train')\n",
    "data_test['yprecip'].plot(ax=ax, label='test')\n",
    "predictions.plot(ax=ax, label='predictions')\n",
    "ax.legend();\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73990aee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error (mse): 3.8642741838572268\n"
     ]
    }
   ],
   "source": [
    "# Test error\n",
    "# ==============================================================================\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = data_test['yprecip'],\n",
    "                y_pred = predictions\n",
    "            )\n",
    "\n",
    "print(f\"Test error (mse): {error_mse}\")\n",
    "# note que gaora se ha reducido el error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d361aaa",
   "metadata": {},
   "source": [
    "# Intervalos de Predicción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2809dc32",
   "metadata": {},
   "source": [
    "Una vez se tiene el modelo final, podemos ver como quedan los intervalos de predicción sobre el conjunto de prueba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "51125866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>2.958860</td>\n",
       "      <td>2.014666</td>\n",
       "      <td>4.202074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01</th>\n",
       "      <td>7.490323</td>\n",
       "      <td>4.680900</td>\n",
       "      <td>8.759032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-01</th>\n",
       "      <td>6.714247</td>\n",
       "      <td>5.365206</td>\n",
       "      <td>8.304792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01</th>\n",
       "      <td>8.833011</td>\n",
       "      <td>7.910852</td>\n",
       "      <td>10.101720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>8.833011</td>\n",
       "      <td>7.888817</td>\n",
       "      <td>10.101720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-01</th>\n",
       "      <td>6.825806</td>\n",
       "      <td>5.881612</td>\n",
       "      <td>8.094516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01</th>\n",
       "      <td>5.130968</td>\n",
       "      <td>4.186774</td>\n",
       "      <td>7.416973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01</th>\n",
       "      <td>6.633649</td>\n",
       "      <td>5.689455</td>\n",
       "      <td>7.902358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-01</th>\n",
       "      <td>6.633649</td>\n",
       "      <td>5.376289</td>\n",
       "      <td>7.876863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01</th>\n",
       "      <td>6.119355</td>\n",
       "      <td>4.849179</td>\n",
       "      <td>7.388064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01</th>\n",
       "      <td>3.940968</td>\n",
       "      <td>3.018810</td>\n",
       "      <td>6.856492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>3.396429</td>\n",
       "      <td>2.036702</td>\n",
       "      <td>6.751548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pred  lower_bound  upper_bound\n",
       "2019-01-01  2.958860     2.014666     4.202074\n",
       "2019-02-01  7.490323     4.680900     8.759032\n",
       "2019-03-01  6.714247     5.365206     8.304792\n",
       "2019-04-01  8.833011     7.910852    10.101720\n",
       "2019-05-01  8.833011     7.888817    10.101720\n",
       "2019-06-01  6.825806     5.881612     8.094516\n",
       "2019-07-01  5.130968     4.186774     7.416973\n",
       "2019-08-01  6.633649     5.689455     7.902358\n",
       "2019-09-01  6.633649     5.376289     7.876863\n",
       "2019-10-01  6.119355     4.849179     7.388064\n",
       "2019-11-01  3.940968     3.018810     6.856492\n",
       "2019-12-01  3.396429     2.036702     6.751548"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps=12\n",
    "Final_Forecaster.fit(y=data_train['yprecip'])\n",
    "\n",
    "predictions = Final_Forecaster.predict_interval(\n",
    "                    steps    = steps,\n",
    "                    interval = [0.25, 99.75],\n",
    "                    n_boot   = 500\n",
    "              )\n",
    "\n",
    "predictions.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0907f436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error (mse): 3.9529592912199987\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x180 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prediction error\n",
    "# ==============================================================================\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = data_test['yprecip'],\n",
    "                y_pred = predictions.iloc[:, 0]\n",
    "            )\n",
    "\n",
    "print(f\"Test error (mse): {error_mse}\")\n",
    "\n",
    "# Plot\n",
    "# ==============================================================================\n",
    "fig, ax = plt.subplots(figsize=(7, 2.5))\n",
    "data_test['yprecip'].plot(ax=ax, label='test')\n",
    "predictions['pred'].plot(ax=ax, label='prediction')\n",
    "ax.fill_between(\n",
    "    predictions.index,\n",
    "    predictions['lower_bound'],\n",
    "    predictions['upper_bound'],\n",
    "    color = 'green',\n",
    "    alpha = 0.2\n",
    ")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9f271a",
   "metadata": {},
   "source": [
    "# Backtesting\n",
    "\n",
    "La idea del backtesting consiste en probar la capacidad predictiva de un modelo sobre el histórico de datos. Este es un caso especial de validación cruzada, acá si se considera conjunto de validación. Existen algunas variantes del backtesting.Para detalles ver https://www.cienciadedatos.net/documentos/py27-time-series-forecasting-python-scikitlearn.html.\n",
    "* Backtesting con reajuste e incremento del tamaño de entranamineto(origen fijo)\n",
    "* Backtesting con reajuste  tamaño de entranamiento fijo(origen rodante)\n",
    "* Backtesting sin reajuste\n",
    "\n",
    "Atención: Independientemente de cuál se utilice, es importante no incluir datos de prueba(por ejemplo de hiperparámetros) en el proceso de búsqueda para evitar problemas de sobreajuste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd369f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train forecaster with the best hyperparameters\n",
    "# ==============================================================================\n",
    "regressor_back = DecisionTreeRegressor(max_depth=10) ####Acá podemos mover tanto la profundidad como el número de lags.\n",
    "                \n",
    "\n",
    "forecaster_back = ForecasterAutoreg(\n",
    "                regressor = regressor_back,\n",
    "                lags      = 12\n",
    "             )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "75dd3944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yprecip</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fecha</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2009-01-01</th>\n",
       "      <td>3.758065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-02-01</th>\n",
       "      <td>4.235714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-03-01</th>\n",
       "      <td>4.764516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-04-01</th>\n",
       "      <td>5.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009-05-01</th>\n",
       "      <td>4.438710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-01</th>\n",
       "      <td>5.548387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-01</th>\n",
       "      <td>6.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-01</th>\n",
       "      <td>6.890323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-01</th>\n",
       "      <td>6.276667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-01</th>\n",
       "      <td>3.667742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             yprecip\n",
       "Fecha               \n",
       "2009-01-01  3.758065\n",
       "2009-02-01  4.235714\n",
       "2009-03-01  4.764516\n",
       "2009-04-01  5.400000\n",
       "2009-05-01  4.438710\n",
       "...              ...\n",
       "2018-08-01  5.548387\n",
       "2018-09-01  6.490000\n",
       "2018-10-01  6.890323\n",
       "2018-11-01  6.276667\n",
       "2018-12-01  3.667742\n",
       "\n",
       "[120 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d04b89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 133.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.1296657147141667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Backtesting con reajuste\n",
    "# ==============================================================================\n",
    "steps = 12\n",
    "n_backtesting = 12*2 # The last 2 years are separated for the backtest\n",
    "\n",
    "metric, predictions_backtest = backtesting_forecaster(\n",
    "                                    forecaster         = forecaster_back,\n",
    "                                    y                  = data_train['yprecip'],\n",
    "                                    initial_train_size = len(data_train) - n_backtesting,\n",
    "                                    fixed_train_size   = False,\n",
    "                                    steps              = steps,\n",
    "                                    metric             = 'mean_squared_error',\n",
    "                                    refit              = True,\n",
    "                                    verbose            = True,\n",
    "                                    show_progress      = True\n",
    "                                )\n",
    "\n",
    "print(f\"Backtest error: {metric}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fe5900bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x180 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot backtest predictions vs real values\n",
    "# ==============================================================================\n",
    "fig, ax = plt.subplots(figsize=(7, 2.5))\n",
    "Lluvia.loc[predictions_backtest.index, 'yprecip'].plot(ax=ax, label='test')\n",
    "predictions_backtest.plot(ax=ax, label='predictions')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "279e9d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 174.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.17684369407752\n",
      "max_depth= 1\n",
      "lags= 1\n",
      "[1, 1, 3.17684369407752]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 182.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.176845572199621\n",
      "max_depth= 1\n",
      "lags= 2\n",
      "[1, 2, 3.176845572199621]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 180.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.1779559983081236\n",
      "max_depth= 1\n",
      "lags= 3\n",
      "[1, 3, 3.1779559983081236]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 174.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.1788229269900037\n",
      "max_depth= 1\n",
      "lags= 4\n",
      "[1, 4, 3.1788229269900037]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 166.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.1815161190343786\n",
      "max_depth= 1\n",
      "lags= 5\n",
      "[1, 5, 3.1815161190343786]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 172.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.180168772586667\n",
      "max_depth= 1\n",
      "lags= 6\n",
      "[1, 6, 3.180168772586667]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 170.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.1802299758889454\n",
      "max_depth= 1\n",
      "lags= 7\n",
      "[1, 7, 3.1802299758889454]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 169.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.1817710308339855\n",
      "max_depth= 1\n",
      "lags= 8\n",
      "[1, 8, 3.1817710308339855]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 168.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.18901633710233\n",
      "max_depth= 1\n",
      "lags= 9\n",
      "[1, 9, 3.18901633710233]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 167.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.1889431894102453\n",
      "max_depth= 1\n",
      "lags= 10\n",
      "[1, 10, 3.1889431894102453]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 173.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.965844428163333\n",
      "max_depth= 1\n",
      "lags= 11\n",
      "[1, 11, 2.965844428163333]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 144.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.1243925433107322\n",
      "max_depth= 1\n",
      "lags= 12\n",
      "[1, 12, 2.1243925433107322]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 172.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.3135672216537917\n",
      "max_depth= 2\n",
      "lags= 1\n",
      "[2, 1, 3.3135672216537917]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 171.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.0576150515440808\n",
      "max_depth= 2\n",
      "lags= 2\n",
      "[2, 2, 3.0576150515440808]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 176.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.3914162510208965\n",
      "max_depth= 2\n",
      "lags= 3\n",
      "[2, 3, 3.3914162510208965]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 172.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.311825579364967\n",
      "max_depth= 2\n",
      "lags= 4\n",
      "[2, 4, 3.311825579364967]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 151.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.2237581298168094\n",
      "max_depth= 2\n",
      "lags= 5\n",
      "[2, 5, 2.2237581298168094]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 165.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.2185983496893686\n",
      "max_depth= 2\n",
      "lags= 6\n",
      "[2, 6, 2.2185983496893686]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 134.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.2233365461380226\n",
      "max_depth= 2\n",
      "lags= 7\n",
      "[2, 7, 2.2233365461380226]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 154.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.2195600925991603\n",
      "max_depth= 2\n",
      "lags= 8\n",
      "[2, 8, 2.2195600925991603]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 160.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.2688202829600823\n",
      "max_depth= 2\n",
      "lags= 9\n",
      "[2, 9, 2.2688202829600823]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 152.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.2583001884432394\n",
      "max_depth= 2\n",
      "lags= 10\n",
      "[2, 10, 2.2583001884432394]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 144.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.8047126243876828\n",
      "max_depth= 2\n",
      "lags= 11\n",
      "[2, 11, 2.8047126243876828]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 157.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 1.6175381116924854\n",
      "max_depth= 2\n",
      "lags= 12\n",
      "[2, 12, 1.6175381116924854]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 174.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.4435700741914914\n",
      "max_depth= 3\n",
      "lags= 1\n",
      "[3, 1, 3.4435700741914914]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 149.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.3799320083986717\n",
      "max_depth= 3\n",
      "lags= 2\n",
      "[3, 2, 3.3799320083986717]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 157.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.6487436278872742\n",
      "max_depth= 3\n",
      "lags= 3\n",
      "[3, 3, 2.6487436278872742]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 157.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.860980639507352\n",
      "max_depth= 3\n",
      "lags= 4\n",
      "[3, 4, 3.860980639507352]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 140.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.7356000401767013\n",
      "max_depth= 3\n",
      "lags= 5\n",
      "[3, 5, 3.7356000401767013]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 154.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.757977167662725\n",
      "max_depth= 3\n",
      "lags= 6\n",
      "[3, 6, 3.757977167662725]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 141.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.7906688538998465\n",
      "max_depth= 3\n",
      "lags= 7\n",
      "[3, 7, 3.7906688538998465]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 137.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.6892664099815033\n",
      "max_depth= 3\n",
      "lags= 8\n",
      "[3, 8, 3.6892664099815033]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 131.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.565624616627706\n",
      "max_depth= 3\n",
      "lags= 9\n",
      "[3, 9, 2.565624616627706]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 134.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 1.7330905414685223\n",
      "max_depth= 3\n",
      "lags= 10\n",
      "[3, 10, 1.7330905414685223]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 125.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.1836741178513783\n",
      "max_depth= 3\n",
      "lags= 11\n",
      "[3, 11, 2.1836741178513783]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 129.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 1.9961137619726703\n",
      "max_depth= 3\n",
      "lags= 12\n",
      "[3, 12, 1.9961137619726703]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 144.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.790891523155272\n",
      "max_depth= 4\n",
      "lags= 1\n",
      "[4, 1, 3.790891523155272]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 142.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.026714229295945\n",
      "max_depth= 4\n",
      "lags= 2\n",
      "[4, 2, 5.026714229295945]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 138.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.2253843111953686\n",
      "max_depth= 4\n",
      "lags= 3\n",
      "[4, 3, 3.2253843111953686]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 131.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 4.192062287640905\n",
      "max_depth= 4\n",
      "lags= 4\n",
      "[4, 4, 4.192062287640905]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 132.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.642052265185523\n",
      "max_depth= 4\n",
      "lags= 5\n",
      "[4, 5, 2.642052265185523]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 122.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.9544145789060985\n",
      "max_depth= 4\n",
      "lags= 6\n",
      "[4, 6, 2.9544145789060985]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 115.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.0405931210427735\n",
      "max_depth= 4\n",
      "lags= 7\n",
      "[4, 7, 3.0405931210427735]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 115.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.400267894952348\n",
      "max_depth= 4\n",
      "lags= 8\n",
      "[4, 8, 2.400267894952348]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 118.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 1.9189500173119314\n",
      "max_depth= 4\n",
      "lags= 9\n",
      "[4, 9, 1.9189500173119314]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 111.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.0140772512677274\n",
      "max_depth= 4\n",
      "lags= 10\n",
      "[4, 10, 2.0140772512677274]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 95.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 1.7848223026178236\n",
      "max_depth= 4\n",
      "lags= 11\n",
      "[4, 11, 1.7848223026178236]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 93.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.1244808123336854\n",
      "max_depth= 4\n",
      "lags= 12\n",
      "[4, 12, 2.1244808123336854]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 123.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 4.222851617721179\n",
      "max_depth= 5\n",
      "lags= 1\n",
      "[5, 1, 4.222851617721179]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 129.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 4.614439553789204\n",
      "max_depth= 5\n",
      "lags= 2\n",
      "[5, 2, 4.614439553789204]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 111.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.1238602379054634\n",
      "max_depth= 5\n",
      "lags= 3\n",
      "[5, 3, 3.1238602379054634]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 146.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.7695121835360816\n",
      "max_depth= 5\n",
      "lags= 4\n",
      "[5, 4, 3.7695121835360816]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 154.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.1296128913645433\n",
      "max_depth= 5\n",
      "lags= 5\n",
      "[5, 5, 3.1296128913645433]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 145.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 4.179718093462239\n",
      "max_depth= 5\n",
      "lags= 6\n",
      "[5, 6, 4.179718093462239]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 148.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 4.158964569137646\n",
      "max_depth= 5\n",
      "lags= 7\n",
      "[5, 7, 4.158964569137646]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 151.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.103646103045109\n",
      "max_depth= 5\n",
      "lags= 8\n",
      "[5, 8, 5.103646103045109]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 146.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.2376869196716584\n",
      "max_depth= 5\n",
      "lags= 9\n",
      "[5, 9, 3.2376869196716584]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 153.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 1.9871079117527897\n",
      "max_depth= 5\n",
      "lags= 10\n",
      "[5, 10, 1.9871079117527897]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 151.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.231786363083584\n",
      "max_depth= 5\n",
      "lags= 11\n",
      "[5, 11, 3.231786363083584]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 148.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.32365354659547\n",
      "max_depth= 5\n",
      "lags= 12\n",
      "[5, 12, 2.32365354659547]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 162.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 4.087378289626755"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "max_depth= 6\n",
      "lags= 1\n",
      "[6, 1, 4.087378289626755]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 156.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.624845133771626\n",
      "max_depth= 6\n",
      "lags= 2\n",
      "[6, 2, 2.624845133771626]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 157.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.881299662540272\n",
      "max_depth= 6\n",
      "lags= 3\n",
      "[6, 3, 3.881299662540272]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 159.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 4.029836221426592\n",
      "max_depth= 6\n",
      "lags= 4\n",
      "[6, 4, 4.029836221426592]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 152.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.6531996840853913\n",
      "max_depth= 6\n",
      "lags= 5\n",
      "[6, 5, 3.6531996840853913]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 161.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.21294091315262\n",
      "max_depth= 6\n",
      "lags= 6\n",
      "[6, 6, 2.21294091315262]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 152.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.6448261193034033\n",
      "max_depth= 6\n",
      "lags= 7\n",
      "[6, 7, 2.6448261193034033]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 159.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.225347924512767\n",
      "max_depth= 6\n",
      "lags= 8\n",
      "[6, 8, 5.225347924512767]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 149.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.6088155476587214\n",
      "max_depth= 6\n",
      "lags= 9\n",
      "[6, 9, 2.6088155476587214]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 154.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.3331735266800098\n",
      "max_depth= 6\n",
      "lags= 10\n",
      "[6, 10, 2.3331735266800098]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 150.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.1414495846365713\n",
      "max_depth= 6\n",
      "lags= 11\n",
      "[6, 11, 3.1414495846365713]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 146.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.687486294694311\n",
      "max_depth= 6\n",
      "lags= 12\n",
      "[6, 12, 2.687486294694311]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 160.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.276797962050132\n",
      "max_depth= 7\n",
      "lags= 1\n",
      "[7, 1, 5.276797962050132]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 163.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 6.536865409802396\n",
      "max_depth= 7\n",
      "lags= 2\n",
      "[7, 2, 6.536865409802396]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 148.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.740763780204537\n",
      "max_depth= 7\n",
      "lags= 3\n",
      "[7, 3, 3.740763780204537]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 168.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.153541244790123\n",
      "max_depth= 7\n",
      "lags= 4\n",
      "[7, 4, 3.153541244790123]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 153.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 4.171242322357327\n",
      "max_depth= 7\n",
      "lags= 5\n",
      "[7, 5, 4.171242322357327]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 149.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.461136933687602\n",
      "max_depth= 7\n",
      "lags= 6\n",
      "[7, 6, 5.461136933687602]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 152.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.752521915193281\n",
      "max_depth= 7\n",
      "lags= 7\n",
      "[7, 7, 5.752521915193281]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 147.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.325996793043132\n",
      "max_depth= 7\n",
      "lags= 8\n",
      "[7, 8, 2.325996793043132]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 144.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.3564637151134655\n",
      "max_depth= 7\n",
      "lags= 9\n",
      "[7, 9, 3.3564637151134655]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 150.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.3336119808010687\n",
      "max_depth= 7\n",
      "lags= 10\n",
      "[7, 10, 3.3336119808010687]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 148.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.998853023593238\n",
      "max_depth= 7\n",
      "lags= 11\n",
      "[7, 11, 3.998853023593238]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 142.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.193397998475813\n",
      "max_depth= 7\n",
      "lags= 12\n",
      "[7, 12, 2.193397998475813]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 158.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.064119051456224\n",
      "max_depth= 8\n",
      "lags= 1\n",
      "[8, 1, 5.064119051456224]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 143.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.368173087680017\n",
      "max_depth= 8\n",
      "lags= 2\n",
      "[8, 2, 3.368173087680017]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 149.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.8001630220653113\n",
      "max_depth= 8\n",
      "lags= 3\n",
      "[8, 3, 3.8001630220653113]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 143.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.2855092333238605\n",
      "max_depth= 8\n",
      "lags= 4\n",
      "[8, 4, 2.2855092333238605]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 160.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.517281204204146\n",
      "max_depth= 8\n",
      "lags= 5\n",
      "[8, 5, 5.517281204204146]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 158.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 6.053882082996431\n",
      "max_depth= 8\n",
      "lags= 6\n",
      "[8, 6, 6.053882082996431]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 144.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 7.580282941861543\n",
      "max_depth= 8\n",
      "lags= 7\n",
      "[8, 7, 7.580282941861543]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 144.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.024451682498126\n",
      "max_depth= 8\n",
      "lags= 8\n",
      "[8, 8, 3.024451682498126]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 138.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.3094399796391176\n",
      "max_depth= 8\n",
      "lags= 9\n",
      "[8, 9, 3.3094399796391176]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 142.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.345959132463326\n",
      "max_depth= 8\n",
      "lags= 10\n",
      "[8, 10, 3.345959132463326]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 136.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.756678448786179\n",
      "max_depth= 8\n",
      "lags= 11\n",
      "[8, 11, 3.756678448786179]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 135.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.775185417749274\n",
      "max_depth= 8\n",
      "lags= 12\n",
      "[8, 12, 2.775185417749274]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 150.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 10.115396380098957\n",
      "max_depth= 9\n",
      "lags= 1\n",
      "[9, 1, 10.115396380098957]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 160.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 6.543166605026379\n",
      "max_depth= 9\n",
      "lags= 2\n",
      "[9, 2, 6.543166605026379]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 150.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.199762239998242\n",
      "max_depth= 9\n",
      "lags= 3\n",
      "[9, 3, 5.199762239998242]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 142.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 6.093693719816514\n",
      "max_depth= 9\n",
      "lags= 4\n",
      "[9, 4, 6.093693719816514]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 139.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.006353563266383\n",
      "max_depth= 9\n",
      "lags= 5\n",
      "[9, 5, 5.006353563266383]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 134.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 7.679938417766588\n",
      "max_depth= 9\n",
      "lags= 6\n",
      "[9, 6, 7.679938417766588]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 123.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 4.812564292562702\n",
      "max_depth= 9\n",
      "lags= 7\n",
      "[9, 7, 4.812564292562702]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 118.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.391617951275118\n",
      "max_depth= 9\n",
      "lags= 8\n",
      "[9, 8, 3.391617951275118]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 122.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.9751857373946033\n",
      "max_depth= 9\n",
      "lags= 9\n",
      "[9, 9, 2.9751857373946033]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 112.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.862552825992845\n",
      "max_depth= 9\n",
      "lags= 10\n",
      "[9, 10, 2.862552825992845]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 112.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 4.394361310317556\n",
      "max_depth= 9\n",
      "lags= 11\n",
      "[9, 11, 4.394361310317556]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 101.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.3550542452483714\n",
      "max_depth= 9\n",
      "lags= 12\n",
      "[9, 12, 2.3550542452483714]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 143.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 9.95684182690056\n",
      "max_depth= 10\n",
      "lags= 1\n",
      "[10, 1, 9.95684182690056]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 125.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.789349727918533\n",
      "max_depth= 10\n",
      "lags= 2\n",
      "[10, 2, 5.789349727918533]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 112.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.193621951148105\n",
      "max_depth= 10\n",
      "lags= 3\n",
      "[10, 3, 5.193621951148105]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 108.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.726039663065488\n",
      "max_depth= 10\n",
      "lags= 4\n",
      "[10, 4, 5.726039663065488]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 105.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 4.593208622229787\n",
      "max_depth= 10\n",
      "lags= 5\n",
      "[10, 5, 4.593208622229787]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 104.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 6.918407751322369\n",
      "max_depth= 10\n",
      "lags= 6\n",
      "[10, 6, 6.918407751322369]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 106.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.204657807995871\n",
      "max_depth= 10\n",
      "lags= 7\n",
      "[10, 7, 5.204657807995871]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 106.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.3859463919860335\n",
      "max_depth= 10\n",
      "lags= 8\n",
      "[10, 8, 2.3859463919860335]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 103.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.9070980210149053\n",
      "max_depth= 10\n",
      "lags= 9\n",
      "[10, 9, 3.9070980210149053]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 106.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.2152151600593037\n",
      "max_depth= 10\n",
      "lags= 10\n",
      "[10, 10, 2.2152151600593037]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 100.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.816442379271836\n",
      "max_depth= 10\n",
      "lags= 11\n",
      "[10, 11, 3.816442379271836]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 88.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.5769772997600877\n",
      "max_depth= 10\n",
      "lags= 12\n",
      "[10, 12, 2.5769772997600877]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 132.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 9.986316556972652\n",
      "max_depth= 11\n",
      "lags= 1\n",
      "[11, 1, 9.986316556972652]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 115.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 4.130024297819163\n",
      "max_depth= 11\n",
      "lags= 2\n",
      "[11, 2, 4.130024297819163]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 156.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.788003980013724\n",
      "max_depth= 11\n",
      "lags= 3\n",
      "[11, 3, 5.788003980013724]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 155.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.072210199273951\n",
      "max_depth= 11\n",
      "lags= 4\n",
      "[11, 4, 5.072210199273951]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 148.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.8305693946962527\n",
      "max_depth= 11\n",
      "lags= 5\n",
      "[11, 5, 2.8305693946962527]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 146.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.312818300910962\n",
      "max_depth= 11\n",
      "lags= 6\n",
      "[11, 6, 5.312818300910962]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 147.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 4.547530531845507\n",
      "max_depth= 11\n",
      "lags= 7\n",
      "[11, 7, 4.547530531845507]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 144.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.2625771540651214\n",
      "max_depth= 11\n",
      "lags= 8\n",
      "[11, 8, 2.2625771540651214]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 147.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.7892259621977655\n",
      "max_depth= 11\n",
      "lags= 9\n",
      "[11, 9, 3.7892259621977655]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 149.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.8276158133217346\n",
      "max_depth= 11\n",
      "lags= 10\n",
      "[11, 10, 2.8276158133217346]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 143.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 4.712222264520475\n",
      "max_depth= 11\n",
      "lags= 11\n",
      "[11, 11, 4.712222264520475]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 139.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.5312445430816495\n",
      "max_depth= 11\n",
      "lags= 12\n",
      "[11, 12, 2.5312445430816495]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 163.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 9.638932986283146\n",
      "max_depth= 12\n",
      "lags= 1\n",
      "[12, 1, 9.638932986283146]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 148.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 6.557520550694508\n",
      "max_depth= 12\n",
      "lags= 2\n",
      "[12, 2, 6.557520550694508]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 157.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.7848904773405727\n",
      "max_depth= 12\n",
      "lags= 3\n",
      "[12, 3, 3.7848904773405727]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 154.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 4.789685749795207\n",
      "max_depth= 12\n",
      "lags= 4\n",
      "[12, 4, 4.789685749795207]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 145.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.7497285984336792\n",
      "max_depth= 12\n",
      "lags= 5\n",
      "[12, 5, 2.7497285984336792]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 151.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.164077832717084\n",
      "max_depth= 12\n",
      "lags= 6\n",
      "[12, 6, 5.164077832717084]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 146.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 6.0539494222336465\n",
      "max_depth= 12\n",
      "lags= 7\n",
      "[12, 7, 6.0539494222336465]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 142.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.3667958589039038\n",
      "max_depth= 12\n",
      "lags= 8\n",
      "[12, 8, 3.3667958589039038]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 152.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.5457052303906593\n",
      "max_depth= 12\n",
      "lags= 9\n",
      "[12, 9, 3.5457052303906593]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 143.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.1700091697772503\n",
      "max_depth= 12\n",
      "lags= 10\n",
      "[12, 10, 2.1700091697772503]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 145.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 4.1499026702803565\n",
      "max_depth= 12\n",
      "lags= 11\n",
      "[12, 11, 4.1499026702803565]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 138.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.589110316582842\n",
      "max_depth= 12\n",
      "lags= 12\n",
      "[12, 12, 2.589110316582842]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 158.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 9.921400310570396\n",
      "max_depth= 13\n",
      "lags= 1\n",
      "[13, 1, 9.921400310570396]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 159.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.235980847298343\n",
      "max_depth= 13\n",
      "lags= 2\n",
      "[13, 2, 5.235980847298343]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 149.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.204597478405746\n",
      "max_depth= 13\n",
      "lags= 3\n",
      "[13, 3, 5.204597478405746]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 152.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.763513239006436\n",
      "max_depth= 13\n",
      "lags= 4\n",
      "[13, 4, 5.763513239006436]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 155.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.7384927946798734\n",
      "max_depth= 13\n",
      "lags= 5\n",
      "[13, 5, 2.7384927946798734]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 155.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 7.344212328147527\n",
      "max_depth= 13\n",
      "lags= 6\n",
      "[13, 6, 7.344212328147527]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 155.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 6.415766544191239\n",
      "max_depth= 13\n",
      "lags= 7\n",
      "[13, 7, 6.415766544191239]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 154.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.401871385280179\n",
      "max_depth= 13\n",
      "lags= 8\n",
      "[13, 8, 2.401871385280179]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 149.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.4387392302859854\n",
      "max_depth= 13\n",
      "lags= 9\n",
      "[13, 9, 3.4387392302859854]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 143.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 4.225942004580919\n",
      "max_depth= 13\n",
      "lags= 10\n",
      "[13, 10, 4.225942004580919]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 151.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 4.127458156739017\n",
      "max_depth= 13\n",
      "lags= 11\n",
      "[13, 11, 4.127458156739017]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 141.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.6757757367189474\n",
      "max_depth= 13\n",
      "lags= 12\n",
      "[13, 12, 2.6757757367189474]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 149.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 9.88204410329571\n",
      "max_depth= 14\n",
      "lags= 1\n",
      "[14, 1, 9.88204410329571]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 152.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.127587024403355\n",
      "max_depth= 14\n",
      "lags= 2\n",
      "[14, 2, 5.127587024403355]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 152.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 6.9361676143702065\n",
      "max_depth= 14\n",
      "lags= 3\n",
      "[14, 3, 6.9361676143702065]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 140.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 8.95591061650248\n",
      "max_depth= 14\n",
      "lags= 4\n",
      "[14, 4, 8.95591061650248]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 138.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.9403353822361993\n",
      "max_depth= 14\n",
      "lags= 5\n",
      "[14, 5, 2.9403353822361993]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 134.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 6.201793484410847\n",
      "max_depth= 14\n",
      "lags= 6\n",
      "[14, 6, 6.201793484410847]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 127.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.316536014166657\n",
      "max_depth= 14\n",
      "lags= 7\n",
      "[14, 7, 5.316536014166657]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 117.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.669872313705804\n",
      "max_depth= 14\n",
      "lags= 8\n",
      "[14, 8, 3.669872313705804]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 119.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 4.679854115895982\n",
      "max_depth= 14\n",
      "lags= 9\n",
      "[14, 9, 4.679854115895982]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 122.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.498855053137753\n",
      "max_depth= 14\n",
      "lags= 10\n",
      "[14, 10, 2.498855053137753]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 110.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.7677929727855854\n",
      "max_depth= 14\n",
      "lags= 11\n",
      "[14, 11, 3.7677929727855854]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 112.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.728315630842463\n",
      "max_depth= 14\n",
      "lags= 12\n",
      "[14, 12, 2.728315630842463]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 134.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 9.957652375807948\n",
      "max_depth= 15\n",
      "lags= 1\n",
      "[15, 1, 9.957652375807948]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 139.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.148509674420699\n",
      "max_depth= 15\n",
      "lags= 2\n",
      "[15, 2, 5.148509674420699]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 136.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 7.769852667945656\n",
      "max_depth= 15\n",
      "lags= 3\n",
      "[15, 3, 7.769852667945656]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 134.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 9.199333700095957\n",
      "max_depth= 15\n",
      "lags= 4\n",
      "[15, 4, 9.199333700095957]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 127.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.9964619206867336\n",
      "max_depth= 15\n",
      "lags= 5\n",
      "[15, 5, 2.9964619206867336]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 125.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 6.835870003585605\n",
      "max_depth= 15\n",
      "lags= 6\n",
      "[15, 6, 6.835870003585605]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 118.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 5.424880439824645\n",
      "max_depth= 15\n",
      "lags= 7\n",
      "[15, 7, 5.424880439824645]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 120.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.6405275590799104\n",
      "max_depth= 15\n",
      "lags= 8\n",
      "[15, 8, 2.6405275590799104]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 104.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.799328014819062\n",
      "max_depth= 15\n",
      "lags= 9\n",
      "[15, 9, 3.799328014819062]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 107.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 3.380006901312585\n",
      "max_depth= 15\n",
      "lags= 10\n",
      "[15, 10, 3.380006901312585]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 110.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 4.03625853614763\n",
      "max_depth= 15\n",
      "lags= 11\n",
      "[15, 11, 4.03625853614763]\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 96\n",
      "Number of observations used for backtesting: 24\n",
      "    Number of folds: 2\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 101.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backtest error: 2.5027250185826646\n",
      "max_depth= 15\n",
      "lags= 12\n",
      "[15, 12, 2.5027250185826646]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Find the best Max Depth\n",
    "\n",
    "# Loop through a few different max depths and check the performance\n",
    "# Try different max depths. We want to optimize our ML models to make the best predictions possible.\n",
    "# For regular decision trees, max_depth, which is a hyperparameter, limits the number of splits in a tree.\n",
    "# You can find the best value of max_depth based on the R-squared score of the model on the test set.\n",
    "\n",
    "steps = 12\n",
    "n_backtesting = 12*2 # The last 2 years are separated for the backtest\n",
    "#resultados = pd.DataFrame(data=None,columns=['max_depth', 'lags', 'Backtest error'])\n",
    "resultados = pd.DataFrame(data=None)\n",
    "for d in [1,2, 3, 4, 5,6,7,8,9,10,11,12,13,14,15]:\n",
    "    for k in [1,2,3,4,5,6,7,8,9,10,11,12]:\n",
    "        regressor_back = DecisionTreeRegressor(max_depth=d) ####Acá podemos mover tanto la profundidad como el número de lags.\n",
    "                \n",
    "\n",
    "        forecaster_back = ForecasterAutoreg(\n",
    "                      regressor = regressor_back,\n",
    "                      lags      = k\n",
    "                    )\n",
    "\n",
    "    # Create the tree and fit it\n",
    "        metric, predictions_backtest = backtesting_forecaster(\n",
    "                                    forecaster         = forecaster_back,\n",
    "                                    y                  = data_train['yprecip'],\n",
    "                                    initial_train_size = len(data_train) - n_backtesting,\n",
    "                                    fixed_train_size   = False,\n",
    "                                    steps              = steps,\n",
    "                                    metric             = 'mean_squared_error',\n",
    "                                    refit              = True,\n",
    "                                    verbose            = True,\n",
    "                                    show_progress      = True\n",
    "                                )\n",
    "\n",
    "        print(f\"Backtest error: {metric}\")\n",
    "        print('max_depth=', str(d))\n",
    "        print('lags=', str(k))\n",
    "        #resultados = resultados.append(pd.DataFrame([d,k,metric],columns=['max_depth', 'lags', 'Backtest error']),ignore_index=True)\n",
    "        resultados = resultados.append(pd.DataFrame(np.reshape([d,k,metric],(1,3))),ignore_index=True)\n",
    "        print([d,k,metric])\n",
    "        \n",
    "resultados.columns = ['max_depth', 'lags', 'Backtest error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a8cc6c7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>lags</th>\n",
       "      <th>Backtest error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.176844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.176846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.177956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.178823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.181516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.640528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.799328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.380007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.036259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.502725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     max_depth  lags  Backtest error\n",
       "0          1.0   1.0        3.176844\n",
       "1          1.0   2.0        3.176846\n",
       "2          1.0   3.0        3.177956\n",
       "3          1.0   4.0        3.178823\n",
       "4          1.0   5.0        3.181516\n",
       "..         ...   ...             ...\n",
       "175       15.0   8.0        2.640528\n",
       "176       15.0   9.0        3.799328\n",
       "177       15.0  10.0        3.380007\n",
       "178       15.0  11.0        4.036259\n",
       "179       15.0  12.0        2.502725\n",
       "\n",
       "[180 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados.columns = ['max_depth', 'lags', 'Backtest error']\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83022815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>lags</th>\n",
       "      <th>Backtest error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.617538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.733091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.784822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.918950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.987108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.921400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.956842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.957652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.986317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.115396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     max_depth  lags  Backtest error\n",
       "23         2.0  12.0        1.617538\n",
       "33         3.0  10.0        1.733091\n",
       "46         4.0  11.0        1.784822\n",
       "44         4.0   9.0        1.918950\n",
       "57         5.0  10.0        1.987108\n",
       "..         ...   ...             ...\n",
       "144       13.0   1.0        9.921400\n",
       "108       10.0   1.0        9.956842\n",
       "168       15.0   1.0        9.957652\n",
       "120       11.0   1.0        9.986317\n",
       "96         9.0   1.0       10.115396\n",
       "\n",
       "[180 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "resultados_ordenados=resultados.sort_values(by='Backtest error')\n",
    "resultados_ordenados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7b9e94",
   "metadata": {},
   "source": [
    "## Modelo Final Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8945dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train forecaster with the best hyperparameters\n",
    "# ==============================================================================\n",
    "regressor_Final_backtesting = DecisionTreeRegressor(max_depth=2)\n",
    "                \n",
    "\n",
    "forecaster_Final_backtesting = ForecasterAutoreg(\n",
    "                regressor = regressor_Final_backtesting,\n",
    "                lags      = 12\n",
    "             )\n",
    "\n",
    "forecaster_Final_backtesting.fit(y=data_train['yprecip'])\n",
    "\n",
    "Final_Forecaster_Backtesting=forecaster_Final_backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcf4d818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error (mse): 0.8539265389147146\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x180 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predictions\n",
    "# ==============================================================================\n",
    "predictions_backtesting = Final_Forecaster_Backtesting.predict(steps=steps)\n",
    "\n",
    "# Plot\n",
    "# ==============================================================================\n",
    "fig, ax = plt.subplots(figsize=(7, 2.5))\n",
    "data_train['yprecip'].plot(ax=ax, label='train')\n",
    "data_test['yprecip'].plot(ax=ax, label='test')\n",
    "predictions_backtesting.plot(ax=ax, label='predictions')\n",
    "ax.legend();\n",
    "\n",
    "\n",
    "# Test error\n",
    "# ==============================================================================\n",
    "error_mse_backtesting = mean_squared_error(\n",
    "                y_true = data_test['yprecip'],\n",
    "                y_pred = predictions_backtesting\n",
    "            )\n",
    "\n",
    "print(f\"Test error (mse): {error_mse_backtesting}\")\n",
    "# note que ahora se ha reducido el error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2e4d8c",
   "metadata": {},
   "source": [
    "## Intervalos de Predicción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "09a8a854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>4.014940</td>\n",
       "      <td>0.175866</td>\n",
       "      <td>7.141935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01</th>\n",
       "      <td>4.014940</td>\n",
       "      <td>0.482831</td>\n",
       "      <td>6.989000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-01</th>\n",
       "      <td>4.014940</td>\n",
       "      <td>0.175866</td>\n",
       "      <td>7.141935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01</th>\n",
       "      <td>7.649140</td>\n",
       "      <td>3.810066</td>\n",
       "      <td>10.776135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>7.649140</td>\n",
       "      <td>3.810066</td>\n",
       "      <td>10.776135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-01</th>\n",
       "      <td>7.649140</td>\n",
       "      <td>2.425186</td>\n",
       "      <td>10.776135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01</th>\n",
       "      <td>7.649140</td>\n",
       "      <td>2.425186</td>\n",
       "      <td>10.776135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01</th>\n",
       "      <td>5.687461</td>\n",
       "      <td>1.848387</td>\n",
       "      <td>8.814456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-01</th>\n",
       "      <td>6.264260</td>\n",
       "      <td>2.425186</td>\n",
       "      <td>9.391255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01</th>\n",
       "      <td>6.264260</td>\n",
       "      <td>3.665449</td>\n",
       "      <td>9.509497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01</th>\n",
       "      <td>6.264260</td>\n",
       "      <td>2.425186</td>\n",
       "      <td>9.391255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>4.014940</td>\n",
       "      <td>0.175866</td>\n",
       "      <td>7.753429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pred  lower_bound  upper_bound\n",
       "2019-01-01  4.014940     0.175866     7.141935\n",
       "2019-02-01  4.014940     0.482831     6.989000\n",
       "2019-03-01  4.014940     0.175866     7.141935\n",
       "2019-04-01  7.649140     3.810066    10.776135\n",
       "2019-05-01  7.649140     3.810066    10.776135\n",
       "2019-06-01  7.649140     2.425186    10.776135\n",
       "2019-07-01  7.649140     2.425186    10.776135\n",
       "2019-08-01  5.687461     1.848387     8.814456\n",
       "2019-09-01  6.264260     2.425186     9.391255\n",
       "2019-10-01  6.264260     3.665449     9.509497\n",
       "2019-11-01  6.264260     2.425186     9.391255\n",
       "2019-12-01  4.014940     0.175866     7.753429"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps=12\n",
    "\n",
    "\n",
    "predictions_backtesting_ip = Final_Forecaster_Backtesting.predict_interval(\n",
    "                    steps    = steps,\n",
    "                    interval = [0.25, 99.75],\n",
    "                    n_boot   = 500\n",
    "              )\n",
    "\n",
    "predictions_backtesting_ip.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aa7e2151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAd4AAADKCAYAAAALriH6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAABHQklEQVR4nO3deXxU5fX48c+dfSb7QsjCvouACIrKKiBUFBFXEJTFqhWlWmoVu+nPtbbWr61V1KptUZCquC9VVFRAUAQEwiZr9oQQss8+997fH0NGIoQlmWQmyXkjryEzd2bOjJN75lnO8yiVlZU6QgghhGgRhkgHIIQQQrQnkniFEEKIFiSJVwghhGhBkniFEEKIFiSJVwghhGhBkniFEEKIFiSJVwghhGhBkniFEEKIFiSJVwghhGhBkniFEEKIFiSJVwghhGhBpkgHIIQQoul0Xae2thZN0yIdSpthMBiIjY1FUZSwPq4kXtFonoAHVVcjHYZoJlajFZNBThGtRW1tLVarFYvFEulQ2gyfz0dtbS1xcXFhfVz5rRKNUumpZHvZdgjvF0ERRYwY6RTfiazYrLB/4xfhp2maJN0ws1gsuN3usD+uJF5x2tx+NzsP7yTGHBPpUEQzK6gpoNRZSp/kPsRaYiMdjhBtgkyuEqfFr/rZWroVm9EW6VBEC7AZbRgUA1tLt7K7fDeqJkML4vgqKyt58cUXG3XfRYsW4XK5whxR9JLEK06ZpmtsPbQVs9EsXY/tjMPsoNpbzYaSDZQ6SyMdjohCVVVVvPTSS42677PPPtssXbrRSrqaxSnRdZ3tZdvRdR2jwRjpcEQEmAwmTJjYX7mfEmcJfZL6YDNLz4cIeuCBBzhw4AAjR45k7NixdOjQgbfffhuv18vkyZP53e9+h9PpZO7cuRQWFqJpGnfffTelpaWUlJRw2WWXkZyczAcffBDpl9LsJPGKU7KnfA/ugBuLQSZvtHc2kw1VU9lUuomMmAy6JnTFoEjnWbS59H+Hwvp4H07qcMLb77//fnbu3MmaNWtYuXIl7777LitXrkTXda677jq+/vprysrKSE9P5/XXXweCreSEhASeeeYZ3n//fVJSUsIac7Q66W/L7bffTq9evbjgggtC11VUVDB16lSGDBnC1KlTqaysbM4YRYTlVuVS7i2XpCtCFEXBYXJwyHWIjcUbqXBXRDokEUVWrlzJypUrGTVqFKNHj2b37t3s27ePM888ky+//JL777+ftWvXkpCQEOlQI+KkLd4ZM2Zw8803M2/evNB1Tz75JGPGjGHBggU8+eSTPPnkkzzwwAPNGqiIjIPOgxTVFmE32SMdiohCFmPwy9jOwztJtCXSO6k3ZqM5wlEJOHkLtTnpus6vf/1r5s6de8xtX331FStWrODBBx9k7NixLFy4MAIRRtZJW7wjRowgKSmp3nUfffQR1113HQDXXXcdH374YfNEJyKq0lPJvsp9knTFSTnMDtx+NxtLNlJQU4Cu65EOSbSwuLg4ampqABg/fjxLliyhtrYWgKKiIg4dOkRxcTF2u51p06Yxf/58tmzZcsx924NGjfGWlpaSnp4OQHp6OocOnXgsYc+ePY15GhFB7oCbH6p+wGqyRjoU0coUFBRgNpjpFtsNh8kR6XDaDZvNhtUaud9Xh8PBueeey3nnnce4ceOYOnUqF110EQAxMTE888wzHDhwgAcffBCDwYDJZOLPf/4zHo+HGTNmcPXVV5OWlsZbb70VsddwPNXV1ZSW/jiTv3fv3k1+TKWysvKkX01zc3OZPn0669atA6BLly7k5eWFbu/atSu5ublNDkZEB7/qZ2PJRmwmmbEqGs/ld5HqSKVnYk+ZCd8C6iYqifBqjve1UVMR09LSKCkpAaCkpIQOHSI3liDCS9VUthzaEhq7E6KxpPZXiONrVOKdNGkSy5YtA2DZsmVccsklYQ1KREZdrS46Uh4iwsJkMGE1WtlfuZ+tpVvx+D2RDkmIiDtpV/PPf/5z1qxZw+HDh0lLS+Pee+9l8uTJzJkzh4KCAjp16sTixYuPmYAlWp8fDv9Ala+qVZcNaTp8Wmjl33tiiDHpzO7tZGRHHwZZaCvidF3Hrbql9reZSFdz82iO9/WUxnhF25dblUuxs7hVr8G8pdzMMzti2F1tpm+CH1dAId9pole8nzm9XYxI8yErXUaeT/WhoNArqRdJdvnCHi6SeJuHJF7RLIprismpzmm1ZUMFTgP/3BXLqoNWOthUbunrZHymFx34vMjK4j0OCl0m+hxJwBdIAo4KLr9Lan/DqKqqivj4+NDPOsFTe11p109/BlBQCP4X/IU4eg32413XHkniFWFX4a5gV/muVpl0a/wKr+x18FaOHZMBZvR0cW13F7afTKANaPBZkZWX98ZQ5DLSL8HP3D5OhqX6JQFHmKqp+DV/m973V9d1dHQ0XTvmr6qpqLpKQAug6RoBPYCqBX9WdfW499XR0fUj13HkOl0nVUmlY0rHU4qpLqnWJePTuc/Ribre9RybuOt+/um/j3fsT6+LFpJ4RVg5/U62HtyK3dy6km5Ag/fzbPx7Tww1foVJnTzc2MdFqk076f0+KbTx8l4HB91Gzkz0M7e3k6GSgCPOo3qwGCytdt9fn+qj1ldLpbcSt9+NR/UQ0ALBxKnr6IrO0TlORw8mMF3BoBhQFAUDwUuFH687HYkkkpacFuZX1ng6x3nNp0hBYf269Tz7zLO8/vrrfPTRR/zwww8sWLDguMdXVlayfPlybrrpJgCKi4tZuHAhL7/8cpNeA0jiFWHkU318f/B7rMbWs0CGrsM3hyw8uzOGPKeJs1N83HZGLb3jT2+PWL8G/yuwsWSvg1KPkYFJfm7s4+TsFH8zRS5OVbTX/qqaikf1UOGpwOlz4gl4QknWqBixGC0RmzQWbYm3IaqqYjSe/P/t12u+5rlFz7Hsv8swG068FelP15oIp+ZIvLI7UTukaipbSrdgNrSecbX91UYW7YplQ5mFTo4AjwytYngjx2rNBpjSxcPFWR4+OpKAF3ybyOBkH3P7uDgrWRJwpBxd+9s9oTtpMZFLJN6AF6ffSYWnAncg2Ir1qT50XcdqtGIyBE+fVqO1VX2BbU75efnMmDaDIUOGsG3bNnr06MHfn/k7F468kOkzpvPVF18x96a5JCYm8sRfnsDr9dKtWzeefOpJYmJj+OLzL7jvD/eRnJzMwEEDUVDwqT6WLF3Cti3beOKvT3Do0CEWLFhATk4OAP/3f//H888/X29LwptuuimUiD0eD7/+9a/ZvHkzRqORRx55hNGjR7N06VL+97//4Xa7OXDgAJMnT+bBBx9skfdJEm87o+s628q2hbqzol25V+Hfu2P4MN9GjFln/hm1XN7VjTkMoVuMMLWrh0mdPHyQb2fpPjt3fpPIkBQfc3s7GZgcaPqTiNPW0vv+qpqKy++iyleF0+fEHXDjVb2ouooBQ6gVa1JMmEyt55SZ+Jfwbj5Qec+fT+m4fXv38cTfnmDYecNYcMcCFv97MQBWq5V3P3yXw4cPc9Ocm3ht+Ws4Yhw8/dTTPP/c89w2/zZ+8+vf8MZbb9C9R3duvelWILimgIKCqgf/P919z92MGDGCpUuXoqoqtbW19bYkBOqtpPjCCy8AsHbtWnbv3s2VV17Jhg0bAMjOzmbVqlVYrVbOOeccbrnlFjp16hS296whredTJMJi1+Fd+AK+qJ9F6lVheY6dpfsceFWFK7q5md3LRbwl/CMjViNc1c3N5M5u3suz8+o+B7/8JolzU33M6e3kzCRJwJEQ7n1/dV3Hq3pDY7GegAd3wI1fC/ZwWAyWeq1Y0TiZWZkMO28YAFddcxUvvfASAJdPvRyATRs3sXv3bqZcOgUAv9/P0HOGsnfPXrp06UKPnj0AuPKaK1n68tLQ49ZN0Fq9ejVP/uNJ/Kofk8FEQkLCCbem/eabb7jlllsA6NOnD507d2bv3r0AjBkzJtSN3K9fP/Lz8yXxivA6UHmAal91VJ9UdB2+KLby/A8xHHQbGZHm5Rf9nHSJPb1x3MawGuGa7sEE/G6enWX7Hdy+LonzO3iZ09tFv0RJwC3t6H1/y1xlp1z7W9eKrfRW4vQHx2K9qpeAFsCkmLAYLSiKgtlgblVDLqfjVFuo4fbTsdi6n+2O4CROXdcZPWY0z/7z2XrHbcvedsoTyhRFwat68Wm+ky74c6Kdso7eVMJoNBIItMzvePT3NYqwKK4ppsRZEtVJd0elifnrEnlwczyxJp0nhlXyyDnVLZJ0j2Y3wfQebpZdeJib+9ayo9LMrWuT+N2GePZUyXfVSLAYLZiNZnYe3smOsh341WArVdd1PAEPZa4y9pTvIbs0m++Kv+Pb4m/ZWraVg86DeALBZSqtRisx5hisJmtUlq20FYUFhWz4LtiV+85b74Rav3WGDh3Kd+u/48D+AwC4XC727dtHr969yMvLI+dATui+xzNy1Ehe/vfLGBQDmqpRVlmGwWZocFvB4cOH88YbbwCwd+9e8vPzw7LDUFNI4m0Hyt3lHKg6ELW1uiVuAw99H8dta5Modhu4Z2AN/xxZwdDUyE5ycphgZk83yy4s5+d9nGwtN3Pz10n8cWM8+6qjb8Zte3D0vr/fl3zPt0XfsqlkE/sq9lHrq0XVVcwGMw6TgxhTTKjrWLSc3n1688ZrbzB+zHgqKyqZNWdWvdtTUlP42z/+xm2/uI3xY8Zz2aTL2LtnLzabjcefeJwbZtzA5Zde3mCX70OPPMTXX3/NuNHj+Nn4n7Hnhz2kJKcwdNhQzjv/PH7/h9/XO/6mm25CVVWGDx/O3LlzWbRoUUS3TwQpJ2rzan21bD20NSr3RXUFFF7dZ+f1A8HYru3uYkZPNw5TdH4ka/0Ky3PsvHHAjjNgYEy6l9m9nfSIa9kWuRDHEw3lRPl5+cyaOYsvVn8RsRg0XcOgGLAarWEpSZNyInFafKqPbYe2RV3SVfVgHe1LP8RQ4TNwUaaHm/s66Wg/8QIYkRZr1pnT28VV3dy8ccDO8hw7q0qSGJvhZXZvF11buEtcCHGsugl47oA7rAk4nKTF20apmsqmg5swKaaoGs/aWGZm0c5Y9tWYGJDk57YzaunfSictVfkUXj/g4M0cO14Vxmd6md3LRWdJwCICoqHFG42a2gKWlavEKdF1nS2lW1A1NWq+6eXVGnl2VwzrSq2k21Vu7VfLmPS2sVlBpVfhtQMO3s6141NhQpaXG3o56RQT3S140bZI4j0xTddCq4udznlREq84JTvLdlLrq42KWt0qn8LiPQ7ezbNjNepc3zPYVWuNju8DYVXuVfjvfgfv5NoJ6HBxlocbernIcEgCFs0vQU845U0S2rO6BGw1WU+pLlwSrzipfRX7KHOXRbxsyK/BO7l2Fu9x4AooTO7iYW5vJ0nWtv9xO+wx8Op+O+/l2dF0mNTJw/W9XKRH+Ri2aN3sqp30hHTMlsh/4Y52dTs8nSwB+3w+vF4vcXFxYX3+JiXeZ555hldeeQVFUejfvz/PPPMMNlvr3Ui9tSusKSS/Jj+im9nrOqw5aOG5XTEUukycm+pj3hm17XLm7yGPgaX7HHyYb0PX4ZLOHq7v6SJNErBoDjrYNTsWgyWq5nVEM13XUXUVq9FKrCX2mARsMBiIjY0N+/vZ6MRbVFTExRdfzLfffovdbmfOnDlMmDCBmTNnhjVAcWrK3eX8UP5DRGt191SZeGZnDJvLLXSNDXBbPyfnpfkiFk+0KHUbWLLPwUf5NhQFJnf2MLPnybcxFEK0DFVT8Wk+UuwpdE/o3uzDdE0qJ1JVFY/Hg9lsxu12k5GREa64xGmo8dWwq3xXxMqGyjwGXvwhhk8KrcRbdH51Zg2TO3swyfIsAKTZNX49oJbrerhYss/Be3k2Psi3MamTh6u6uaUMSYgIMxqM2A12arw1bCjZQAdHB7oldGu2BVia1NX87LPP8vDDD2Oz2Rg3blxoF4if2rNnT6MDFCfmDXjZWb0zImO6Xk3hf4fS+eBQRzQUJqaUcllaCTFGSSQnUuqz8H5pBmsrk/HrBgbFVvGz1IMMiK1pE7O8hWjtVF0loAZItaWS4cjAqPw4GzQcy002OvFWVlZyww038O9//5uEhARmz57N5ZdfzrRp05oclDg1AS3AppJNJ90kujmsPWjhye2xHPIYGZPu5Za+tWRJ+cxpqfAqvJ9n5+1cOxU+A91iA1zVzc2ELA+2NjjrW4jWJqAFUHWV9Jh0Osd3DttWqo1+lC+//JKuXbuSmpqK2WzmsssuY/369WEJSpycpmtkH8rGqBhbPOluKTdz36Z44s06T51fyQNDqiXpNkKSVWdWbxevjT3MbwdVYzLoPLEtjmtXpvDiDw4OeaSvXohIMhlMWI1WSp2lfFf8HfnV+eF53MbesVOnTmzYsAGXy4Xdbuerr77i7LPPDktQ4uR2Hd5FQA20eK1ugdPIHzfG08nm47m+ucQqOlS0aAhtjhWYEgOX9YddVSY+zLexeruFr3fABWleLunkpWd8y67upRsM+OITkL5vIQidZ4tri+kc37nJj9foxHvOOecwZcoUxowZg8lkYuDAgcyZM6fJAYmT21uxlxpfTYuP61b5FBZ+F0+c6mb99odJ/l9eiz5/ezAMmHXSo1pGed9+7J96NZ6U1EiHIsKoyqeQW2ukV3wAh6zWf1osxhPv/XuqZAGNVqagpoCC6gJsppat1fWp8Jv1CeypUNie9xc65+wi5+JL8cfEtmgc7Y1XhewKMxvLLFT6DMRbNIam+BiU7G/WcWBrVSVZX65E0TQKxk+gYMw4dJOcpVszVYf3cm28tDuG2oABAzo94wMMSAowIMnPwCS/1JifgsEdBzf5MSTxtiJlrjL2VOxp8VpdXYdHt8TxaaGV9YefZci2r9lz1TQOnndBi8bRnql6cELb8hw7W8ot2Ix6qBypU0zzzCK3VFXS/f136LB1M64Oaey74hqqekV2A3HRONsqTPxteyx7q80MSfExpYubfTUmtlWY2VlpxqMGhxTSbCoDkvxHEnGA7nEBKQv8CUm87UiNr4bsQ9kRqdX9zx4H/9kTw/La15m64V3yxk8k72eXtHgcImhPlYnlOXY+L7Ki6nB+mo9rurk5O8XfLEOyiT/spOfby7GXH6Z0yDkcuPRy/GFeQk80j3KvwvO7Yvmk0EaqTeX2M5xcmO6t9zkJaLC3OpiEt1UEL8u8we4Uu1Gjf+KPLeL+SYGo3S+7pUjibSc8fg+bSze3ePcywKeFVh7ZEs+fvSu5a91LlA45h93TZsqkmyhw2KvwXq6dd/PsVPoM9IgLcHU3N+MzPWHfhMLg99Fp5Wd0+vJzNIuFnIsnU3LeBWCQ5lA0Cmjwbp6df+124FUVru3u5vpezlMa09V1KHEb2F5hZluFmewKM/trjOgoGNDpER9gwJFkPCDZT0eb1q5OB5J424FI1upuLTdz1/oEZvu2sGjtE1T36Mn2G38hY31RxqvCyiIrb+Q42F9jItGicXkXN1O6ukkJ86YU9tKD9Hx7OYn79lDTuQt7r7wWZ1ansD6HaJqt5Wb+vj245/W5qT5+2b+WLk1cHc3pV9hRaQol4h1HdU+n2lQGJvlDY8U923j3tCTeNk7TNTaXbkbX9BbfV7fAaeC2tUkM8+Ty/vqH8SUlsXXeHaj2yK0FLU5M1+H7w2aW59hZV2rBqMD4TC9Xd3PTOyGM5Ui6TofvN9L9g3cwO50UjRhN3sRJqLJBSkQd9hh4blcMnxbZ6GhTub1/LaM6Ns+e1wEN9teY2FZhIvtIy/iQJ3iOshl1+if6Q2PF/RMDxJrbTpppNYk3uzQbg2II/VUUBbPBjMlgqndpNBgxGowYMAQvjxzfWum6jqZraLqGqquhS1VT8ak+AloAv+YPrY5Sd3zdsV7Vi4LSbOuFNqTap3D7ukRiqitZv/k+jApsmf8rfIlJLRqHaLwCp5G3cmx8VGDHoyqclezj6m5uhnf0YQzTidjoctHt4w9I/3Ydvrh49k+5gsMDz5JhiBYW0OCtHDv/2evArylM6+7i+l6uFl/97KDbEGoRb68wsa/ahIaCgk73uKMnbflJt7fe7ulWk3g3H9x8zHV1CUnTtWDCOfIHnXpdqgpKKFkblWBSNhgMwUslmKAVFAwGAybFhNloxqSYsBgtGBUjJqMpeJxiDF021GWr6RqqptZLfgEtQEAL4FN9qLoauvxpkqzbXkrjqNekaeiKDkfeYR0dBQVFCb6mutdQ9/qigU+Fu79LIL/Mz46dD5BYXUb2vDtwZmZFOjTRCDV+hY/ybbyVa+eg20iGXeXKbm4u6eQhJkytkNi8HHq99QaxRYVS+9vCvj8c7FbOqTVxXgcvv+zvbLZZ7qfLFfixe3pbhZkdlSZcgWBDKsWq1itj6hXferqnW3XibQ4/TeaqrqIrOoqugEIwASpgwBBKfnUbItclfwgep6OjKEowqWOol/yjJUmGm67Dn7bGsTLfxPYDf6J74W523PgLKvv0jXRoookCGnx90MIbOQ62VZhxmDQu6eThym5uMh1hqN1UVTLXraHLxx9J7W8LOOQx8OzOGFYW20i3q8zvX8uItObpVg4XVYf9NUa2lZtDyfjgUd3T/RJ+LGMamOyP2tnTknhFWL28x8G/djtYVfQMw/esY/e111F6znmRDkuE2a7KYDnSF8VWNB1GdPRxTXc3g5KaXo50bO3v1VT16hOewAV+Dd7MsbN4j4OArjCjh4sZPV1hn8XeUkqPdE/XlTHtrTGh6QqJFo0FZ9YwJiP69vOWxCvC5vMiKw9tjmfx4f8yM/t9cidcTP6EiyMdlmhGZR4D7+TaeC/PTrXfQO94P1d3czM2w4uliSfyerW/Zw/lwOSpUvvbRBvLgt3KeU4Tw9O83H5G29sRzBWA7RVmXvghht3VZsZmeLjzzFoSLdHT+pXEK8Iiu9zEr9cncm/l59y/6d8cPGcYe665TibJtBMeFT4rtLE8x05OrYkki8bUrm4md2laOVK92l+zmZxJkyk5b7jU/p6mUreBRTtj+LLERqZD5Zf9a7kgLfpaguEU0ODV/Q5e3uMgzqzz6wE1jEqPjtcsiVc0WaHTwG3rkri0Ygv/2fh/VPXqzY65t6AbW2nflWg0XQ+2qt7IsfPtIStGRWdEmo/JXdyck+rH0MjvYfbSg/R8ZzmJe6X293T4VHjjgJ1X9sWg6XB9TxfTerTebuXG2Fdt5E9b49hbbeaiTA+/7F9LQoRbv5J4RZPUlQ11PpzP55sewpuSQva8O6QeU5Bfa+TDAhv/K7BR5TOQbleZ3NnDpM6NbAUfU/s7iryJl8hnrQHrD5l5anssBS4TIzsGu5UzwjEJrhUKaLB0n4OX9zpIsGjcNaCWER0j1/qVxCsaza/B3esTqC6p4vut92MyKsFa3YTESIcmoohPhTUHrXyQb2PTYUuTW8FGl4tun3xI+jdrpfb3OErcBp7ZEcvqg1ayHAHuOLOW8zr4Ix1WVNhTbeSxLfHsqzExMSvY+o2LwMIcknhFo+g6PLY1jm9yVHbsup8UZwVbb7sTV3pGpEMTUazBVnAnDym202uNxeblHqn9LZDaX4LLfr52wMHSvcFNUG7o5eLa7q4mT3Jra/waLNnr4JV9DpKOtH6Ht3DrVxKvaJRX9jp4ZZeFjXv+RN/SvWz/+S+k5EOcsp+2gg1HWsGXnW4ruK7295OPUNRWXPur61gryokpLiampIiYokJs5YdDC+ecjDOgUOox4NcU4swaqTYNczvvAHBmZnLg0ssJxMQc9/bdVSYe2xrH/hoTP8vyML8FW78RT7yVlZXccccd7Ny5E0VRePrppxk2bNgxx0nijR4ri6w8+H0cK3KfZlzON/ww/XoODTkn0mGJVqrAaeSD/Pqt4Es7e7jkNFrBran21+D1ElNSTExxIY7iYmKKi4gpKcLk8YSOcaek4k7tgH6S2dseVSGn1kS514DdqNE9TiXR0j7HcY+m6DqJe37AHxPL7mkzqOp9/AV8fCq8vNfBq/sdJFs17h5Qy3ktMNs74on31ltvZfjw4cyaNQufz4fL5SIxMfGY4yTxRodtFSYWfJvIPwr+y027PyDn4kspGDch0mGJNsCnwtelVt7Pq98KntzFzbmn2AqOqtpfTcNaUU5scRGO4qJggi0uwn64LHRIwGbDmZ6JMyMTV0YGzowsnOkZaFbrCR/aq8Kr+4IJw6jA7F5Oru7uxixVViExBfn0/e8rOEpLKRw1hpyLJ6Obzcc9dldlsPWbU2vikk5ubjvD2aybMkQ08VZXVzNy5Ei2bNly0iUUJfFGXpHLwLy1Sdxc9DmPbfsPJcMuYO9V18qkFhF2BU4jHx5pBVf6DHQ8aiw49SSt4EjU/ho9HhwlR5JrUbAF6yguxuTzAqArCu6UVFwZmTgzs44k2wy8Scmn9fuj67C21MLTO2IpdhsZm+FhXj8naXZp5R6Pweej20fvkbl2Dc70DH6YMavBeSg+FRbvjWHZPjspNo17BtZwbjNNSoto4t26dSu/+tWv6Nu3L9u2bWPw4ME89thjxBynT/69De81OVDReE7VyIP7+nJeyQ5e3/okxV26sWry5SftChOiKfyawqbqRL4oT2WHMx4DOmfHVzI2uYwBsdUnbAXHVZRz7pefk16QT1nHdL4bexEVHdKaFpCuE1dVSWLZoSN/y0g6XEZsdVXoEJ/VSkVKKpWpHYJ/U1KpTElFbaC1daoOeq28UtSZrbUJZFnd3JCZR//Y2qa9nnYiM2c/5322AovPy+bho/jhrLMb/MKzz+XgnwXdKPbauTDpENdlFGA3hveLzZRzpjT5MRqdeL///nsuuugiPvnkE8455xwWLlxIXFwcf/jDH445Vlq8kePX4J7vEjDlFrBqy0N409LYeusvT9odJkQ4NaoV3ITaX6PbFRyLLQq2ZIMt2mKM/uAYoK4ouDt0CHYPZ2QGW7GZmcFyujD2AnnU4Czc1w44MBt05vRycWU3d6vZiSdamGtr6PXGf0nZuZ2K3n3Zc+0MfAkJxz3Wq8J/9sTw2n47HWwadw+q4ZzU8LV+I9riPXjwIBdddBHZ2dkArF27lr/97W+8/vrrxxwriTcydB3+kh3Ljj21bM6+D7PVyJb5C/DHxUc6NNFO+bXgjOijx4KHp/m4rLOHczocf6/gE9b+ahr2skPB5FpcFBqTtVVW/PicDseRBJuBKyOT2ows3B07opktzfY6dR1WH7TwzI5YDnqMXJQZ7FY+3bIrcRRdJ/3btXR//x00s5m9V00Lfg4asL0iOPab7zRxWWc3885whmXHo4hPrpo0aRJPPfUUvXv35k9/+hMul4uHHnromOMk8UbG0r12lm+HLdvuJ81XxZbb7sTdMT3SYQkBQIHTwIf59nqt4LoZ0cdrBR9d+1vdtTuKGsBRUoIxEGzN6AYDrg5pwRZsRmZwTDYjE198QrPOZQhocNhroMxjCF2uK7XyXZmFHnEB7jyzlrOSZRGMcLGXHqTPf5cQV5BPybnnceCyKxrsBfGq8NLuGN44YCfNrrFwYA1Dmtj6jXji3bp1K3fccQc+n49u3bqxaNEimdUcJb4otvLYBhvf7HqUM8v3s+3m26ju0TPSYQlxDP+RvYLfy7OfvBWsqmSsW0PGuq/xJSSGkqwzIxNXx/Sw1gCrOlT6FA57jJR5DJR5DRw+5tJIhe/YfuNYk8ac3i6mdpVu5eagqCqdP/2Yzl98hic5hd3Tr6ema7cGj88uN/HnrXEUuExM7eLmln61OBr5UYl44j1Vknhb1vYKEwu+ieet3U9zceF6ds2YRdngIZEOS4iTqmsFf1xgo+IUWsGNoetQ7VfqJdFDXuMxSbXca0DT67eUFXSSrBqpVo0UW0OXKokWvdGbSohTF39gH33+uwRrVRX54yaQN34iNLDBi0eFl36IYXmOnXS7xsJBNQxOOf3WryRecYziI2VDD+9dxq37P+LAJZdReOH4SIclxGmpawW/n2dn45FW8AVpPqacYCxY18EVUI7bMi3zGOt1B/u1Yx8g3qyRYg2uHJVqU0P/Pvoy2apJCzbKGN1uer77JmmbNlDdpSu7p1+PJ7VDg8dvLTfz2NY4ilxGruzq4ua+Tuyn0fqVxCvqqfEr3L42kav2fc7ju16m6IKR7J96ldTqilbtmFawTWVcphdND46tHvLUJVgjHvXYz7rDdFRCrZdMf0yuyVatXW231xalbt5Er7ffQFFV9l9+JQfPOa/Bc587AC/ujuHNHAeZDpV7B9Uw6BTH4SXxipDAkbKhzru38sa2v1HRrz87Z93YYLeLEK3NT1vBFoNeL4k21P0bjpmsonWwVFbQ579LSdy/l7IBg9h71bQG13sG2HzYzF+y4yh2Gbiqm5ub+jqxneSUKYlXAMEutsezYynbUciXWx/Gm5FB9i9uR7NIra5om7wqWAzSmSOOQ9PIWvUlXT/5EL8jhj3TZlLZ5/jrPQO4AvDPH2J5J9dOJ0eAhYNqGJgcaPB4SbwCgFf32flss5MNW+7H4rCwZf6v8MdGaI1bIYSIAjGFBfRd9gqO0oMUjhxDzqSG13sG+P6wmT9vjeOg28A13d38vI/zuMMPkngFXxZb+Me3BjZm309HtYatt92JO61jpMMSQoiIC673/D6Za1cH13u+7gZcGZkNHu8KKDy3K4b38ux0jglw76Aazkyq3/qVxNvO7ag0ce/XDlZmP8rA6hy23XIbNd16RDosIYSIKkm7dtD79WWY3C5yJk2maOSYE268saHMzONb4zjkMXBtDzdze//Y+pXE244VuwzM/zqBf2c/zaSDG9g1czaHBw2OdFhCCBGVTLW19F7+X1J2bKOyVx92T5sRXJu7AU5/sPX7fr6dLjEB7j2rhv6JAUm87VWNX+GX6xJZsHUZt+d9zP7JUykafWGkwxJCiOim63Rc/w093nsbzWRi71XXnrTB8t0hM49nx1HmMTC9h5tFY3o3OQxJvK1MQIOF3yUwcsvnPLF3CUUjRrN/yhUyvVMIIU6R7VApfZe9QlxBPgfPGcb+KVeecNerWr/Cop0xfFRgp3JuVpOfXxJvK6Lr8MS2WMybsnlt+1OUDxjIruvnNOsm4UII0RbVW+85KTm43nO37ie8z7elFn4xsH+Tn1vO2K3IawfsHN6Wz9Jdi6jt0oXd110vSVcIIRpBNxrJu/hSsm/9JYquM+jZp+iy4n8oqtrgfc5L84XlueWs3UqsKrGwclM1H2x/AjUxgR1zbm7W/USFEKI9qO7eg+9/dTelQ86hy2efMPDZp7CVHWrW55TE2wrsrDTxz/U6n2z7C3azzvaf/4JAbGykwxJCiDZBtdvZM20mu2bOxnGolLP/9jgdv10XHN9rBpJ4o1yJ28BD39p4O/sJMv2V7Jxz8wl33hBCCNE4ZWedzaYF91DTuSu933yNM17+FyZnbdifRxJvFKv1K/xufRyLti5icNUBfrjuhhNu9iyEEKJpfIlJbLt5HgcunULSrh0M+b+/kPjDzrA+R5MTr6qqjBo1imnTpoUjHnFEQIMHNsXxq82vMvnQJvZffgXlAwZFOiwhhGj7DAYKx4xjyy8X4Hc4GPDS8/R49y0M/iiZXPXss8/St2/DOz+I01PhVVh+wM6taxMZ9f1n3Fb4KQWjx1I8YnSkQxNCiHbFmdmJLXf8mqIRo8j8ehVnPfV/YXlcU1PuXFhYyIoVK7jrrrtYtGhRg8f1e/lfTXmaNk/T4bDHQKnHgOo1MAa43Ohn7MEtHBo0mJxLLot0iEII0S5pZgv7L7+K8n796fPaq4SjzdukxPvb3/6WBx98kJqamhMeZywuasrTtFlezYBTNeJWTWhAB0Wnq1HFYQxg1nUO9O3HtyNGoxUWRDpUIYRo1/IcMfwwfSY/C8NjNTrxfvzxx3To0IHBgwezevXqEx67feEfGvs0bc7+GiOfFtr4tMhKmceIw6QxJt3LxCwvZyX7Mfxk5cdOkQlTCCFEM2l04v3222/53//+x4oVK/B6vdTU1HDLLbfwz3/+M5zxtQmHPQY+L7KyosjK3mozBkVnWKqP2/o5GdHRe9zNlluDgBZAb6Y6t3BQFAWToUmdOkIIEXZhWat59erVPP3007z22mvHvb09rtXsDsDqg1Y+LbSxscyMhkK/BD8TszyMzfCSZI3ehHUqvKqXeGs8iZbESIfSIJ/mo9RVSkALYDfZIx2OEKINCMe2gNIcCCNVh01lZlYU2lh90IpHVehoV5nR08WELC9dYxteA7Q18at+4i3xnJFyRqRDOaku8V0o95RTUF1Arb8Wh8mBIjs5iXbOHXBjMVgwGlppd1srJ7sTNZGuw94j47afF1k57DUSY9IYmxEctx2QdOy4bWumaipGg5FBaYMwKK1r/RWnz0ledR4V3gosBot0Q4t2JaAF8Gk+4i3xZMZmUumtpMxVhqqr0iN0GqTFG0Gl7iPjtoU2DtSaMCk656X5mJhZy/lpvlY7bnsiuq6joXFWh7NaXdIFiLHEcEbqGQS0AAU1BRx0HkRHx2ZseB9OIVozXddxBVzYTDY6xnQkPSYds9EMQLI9me4J3an0VFJYW0i1r1q+kLYQafGeBldA4asSC58W2vj+sBkdhTMT/Uw4Mm6bYGnd47Yn4wl4OLvj2VhN1kiHEha6rnPIdYjC2kLcATd2o126oUWb4FN9aLpGgjWBrLgs4q3xJ72PX/VTVFvEIdchfKoPu0l+H44nHC1eSbwnEdBgY5mFFYVW1hy04tUUMh0qEzI9TMjy0ClGi3SILcIVcDGowyBiLW1zV6RqbzX5NflUeaqwGq0y9iVaHU3X8AQ8OMwO0hxpdIzp2OjPcbW3msKaQqq8VRgUAxajbEFaR7qam4muw+5qEysKrawsslHhMxBv1ri4k4eJWR76JwZoT18E3QE3/ZL7tdmkCxBvjedM65n4VB951Xkcdh8GwGpsG6170XZ5VA8KCkm2JPql9MNhdjT5MeOt8cRb41E1lRJnCQddB/H4PdhMtlY5zBRtpMV7lBK3gc+OLG6RW2vCbNC5IM3HhEwP56f5MLfDz5tH9dAlrguZcZmRDqVFabpGSW0JRc4i/KpfJp+IqKJqKl7NS6w5lvSYdFIdqc2eEJ0+JwU1BVR6K9v13IhW09V8xcf7sBjAYtAxG3QsRoKXhrrL4L8tRh3z0cfV3W7UQ/c/+jqzAYxNbHnW+hW+KrGyotDKlvJgd8qgJB8TsrxcmOElzty2x21PxKt6SXOk0T2xe6RDiagKdwX5NfnU+Gqwm+zyjV9EjDvgxqgYSXWkkhWbFZH5FpquUeYqo8RZQo2vBpvR1q6GZlpNV/PeahM+TcGvgU9V8GsKPg10mt5fa1R+TNaWekn96CTOkeSt1/sCcNhrZG2pBb+m0DkmwI19nEzI9JDhaB/jtidSV6vb3pMuQJI9iSR7Et6Al9zqXMrd5RgVY2h2qBDN6egyoH7J/Ui0JUZ00pNBMZAWk0ZaTBregJeC2gLKXGVouiY9Q6coYl3Nuh5ccMKnKfjUI5caR5LysUm63u3qkdu1Hy+Pfhx/vWN/fEzf0fdRFWxGndHpXiZkeemX0L7GbU9E1VRMRhODOgySWY3HoWoqRbVFlDhLZFUs0Sx0XccdcGM1Welg70BGbEZUf9HTdb3dlCW1mhbv8SgKmBQwGXQcJoD226UbTepqdQekDpCk2wCjwUjn+M50iusUWhXLGXBKOZJosqPLgHom9TylMqBooChKqGdIypJOrm1+JRGN5tN8nN3x7HY1ZtNYiqKQYk8hxZ6Cy+8iryqPcm95m/62L8KvrgzIbrbTKa5Tk8qAooHZaKZrQle6JnSl2ltNQU0B1d5qKUs6ipwdRIg74GZgh4Hyy9EIDrODfqn9ZFUsccqaowwo2sRb4+lv7R8qSyp1leL2u9t9WZKUEwngx1rdJHtSpENpE+qtiuV3S3ebAILzAzyqhzhLXIuVAUWbo8uSoPXVyrfqMV4RPdwBN93iu0nSDSNFUUIzP2t9tcHNGTwVWI1W6YZuh+rKgFIcKXSK7dRmll1tjBhLDH1T+rbrsiQ5A7RzHtVDekw6GXEZkQ6lzYq1xNI/tT9+1U9eTR5lrjKg9X3TF6cn2sqAos1Py5Lya/I57D7cLsqSpKu5HfNpPuLN8fRL7RfpUNqVulWxyj3l6Hr0zubXdA2P6kHVVQwEJ8a0t27RU6XpGj7Vh6qrmAwmbEYbibZEMmMzo7oMKNrUlSXlVefhVt1ROUdCuppFowW0ADajjb4pfSMdSrtjUAxkxmW2mmU4vQEvTr+TCk8F7oAbj+rBp/rQdR2LwdLuEotf9ePTfCiKgtVoxWa0YTfbSbQmEmuJlcmJTXB0WVJhTSG51bltskyv0Ym3oKCAW2+9ldLSUgwGA7Nnz2bevHnhjE00E03X0NE5M/XMNveBFuFnNVmxmqwk25ND12m6hjvgpspTRY2vBk/AE2wda2ooIbX21rGma3hVL7quYzQYsRlt2Ew20hxpJNgSZPnQZpYVl0WyLZkdh3egqmqb+kLT6K7mkpISSkpKGDx4MDU1NVx44YUsXbqUfv2O7baUrubo4lW9nN3x7Db1QRbRwaf6qPXVUumtxO0Pto69qhd0MBvMUds69qk+/Jo/VGtqM9pwmB0k2ZJwmB3yuxJBuq5zoOoAJc4SHKbIl1xFtKs5PT2d9PR0AOLi4ujTpw/FxcXHTbwierj9bs7qeJacSESzsBgtJNuTT9w6Vj14ApFpHauaik8Lrg5lNppDXcXpMenEW+PbfX1pNFIUhR6JPUi2JbO7fDcGxdDqKwPCEn1ubi7Z2dkMHTr0uLfn5eeF42lEE3kCHnrG9aTQXRjpUEQ7ZcCA48gfv+YPJmR/VbBlrHmDY8fomAwmzIamtY79mp+AFkBBwWK0YDUEk2y8OR6HyVHv5F1z5I+IbvF6PDm1OVT7qrGZIjPxKiomV9XW1jJr1iweffRR4uOPv65ol85dmvo0ooncATc9EnvQMaZjpEMRokF1yydWe6up8laFuqoDWgD0YAnWT2s96/amBTAZTFiNVuwmO/GW4GbusnhJ29KPfhx0HuRA5YFWO9O+SYnX7/cza9YsrrnmGqZMmRKumESYeVQPmbGZknRF1DMoBhxmBw6zg/TY9ND1ftVff2Z1wAOAzWQjxhZDgjWBGHNM1I4hi/DqGNORJFsSO8t24lE9ra4mvtGJV9d15s+fT58+fZg/f344YxJh5NN8JFmT6JrQNdKhCNFoZqOZRGMiibbESIciooTFaGFQ2iDyq/MpqC2IiolXp6rRbfRvvvmG1157jVWrVjFy5EhGjhzJihUrwhmbaKK6vWL7JPeJdChCCBF2iqLQJaELgzoMCo3ptwayclUbpekaGhpnp8kWf0KItk/TNfZW7KXMVdasOz2FY3JV6xuVFiel6zo+1cdZHc6SpCuEaBcMioE+yX3ol9IPb8CLqqmRDqlBknjbII/qYVDaIJloIoRod5LtyQzNGIrFZMGjeiIdznFJ4m1j3AE3Z6Sc0SY31RZCiFNhMpgY2GEgXeK64Aq4om4zEkm8bYjL76JHYg+Z+SmEEEBmXCZnp52NhoZP80U6nBBJvG2EJ+AhKy5LanWFEOIodrOdIR2HkGpPxR1wRzocQBJvm+DVvCTbkqVWVwghjqNuvef+Kf3xqb6Ilx1J4m3lAloAh8lB7+TekQ5FCCGiWoItgaHpQ4k1x0a09SuJtxXTdA1FUWRfXSGEOEVGg5F+qf3oldgLd8CNpmstHoMk3lZK13X8qp9BHQa1ykXChRAikjrEdGBo+lCMijG4Z3QLkjN2K+VVvVKrK4QQTVC33nNmbCYuv6vFnlcSbyvk8rs4I+UM7GZ7pEMRQohWTVEUOsd3ZlBacL1nv+pv9ueUxNvKuANueif1JsGWEOlQhBCizYi1xDI0fSgJtoRmb/1K4m1FPAEPneI60SGmQ6RDEUKINqel1ntu9H68rY2u66i6SkALoOoqypE/uqKDDihgVIwYFSMmQ/S9LV7NS7I9mc7xnSMdihBCtGl16z3vPLyTWl8tdlN4h/WiL8OcJk3XCGiBegXRBsWA0WDEbDBjMphClzaTDYfJgcVkwWwwYzaYQ/f3a348AQ/ugBt3wI2qqaH9HQN6AFVV0Y/8qUvORsXYImU8AS1AjCmG3klSqyuEEC2hbr3nopoicqpzsBvtYTvfR23iDWgBVE0lQACF4IutS3hHJ1OL0YLNaMNusocS6um0WI2KEaPBiBUrsZbYBo/TdT048K758QV8oQRdl7TrLlVNrVcXVhdvY0t+NF3DYDDQP7W/1OoKIUQLy4zLJMmWxI7DO8LW9dykxPvZZ59x7733oqoqs2bNYsGCBSc8Xtf1UAuybvEHAwYMBgNmxRxKUnWtU7vJjs1kC7ZOjeaI1qsqioLFaMFitBBjjiGJpAaPrUvCvoAPjxpsRdctUxZqRR/p8gbQ0TFhwmio381d934NSR8itbpCCBEhdes9H6g6EJbHUyorKxu1X5KqqgwdOpR33nmHzMxMxo4dy0svvUS/fv2OOXbboW2h5Gkz2nCYHViMP7ZO22tLTtM1/Kq/Xje3J+AJJeaAHqBfcj8pGxJCiDak0S3ejRs30qNHD7p16wbAVVddxUcffXTcxDugw4BGB9iWGRQDVpP1pN3cQggh2o5GJ97i4mKysrJCP2dmZrJx48bjHrtnz57GPo0QQggRNXr3bvok10YnXl0/9R7qcAQqhBBCtAWNnrGTmZlJYWFh6OeioiIyMjLCEpQQQgjRVjU68Q4ZMoR9+/aRk5ODz+fjzTffZNKkSeGMTQghhGhzGt3VbDKZePzxx7nqqqtQVZXrr7+eM844I5yxCSGEEG1Oo8uJhBBCCHH6ZFUGIYQQogVJ4hVCCCFaUJtOvMnJyYwcOTL0Nzc3t8FjL730Ur7//vsWjA4SExO55ZZbQj8HAgF69uzJtGnTWjSOE3n//fdJTExk9+7dkQ6lntbw3gH1at2j2cnijMTvR7R+9ur89a9/5fzzz2f48OGMHDmSDRs2RDqkegoLC7nuuusYMmQIgwcPZuHChfh8vgaPX7RoES5X8+5DC8Hf3d///vehn//xj3/wpz/9qdmf91TV5Y3zzz+fESNG8PTTT6Np2snveBrCknij9eRit9tZs2ZN6G/Xrl0jHVI9MTEx7Ny5E7fbDcAXX3xx2iVZgUDg5Ac1wZtvvskFF1zAm2++eVr3U9Xm2ceyTjjeOxHdGvvZawnr16/nk08+4auvvmLt2rW8++67UXUe1HWdG264gUsvvZRNmzaxceNGnE4nDz30UIP3efbZZ0O/T83JarXy/vvvc/jw4WZ/rsaoyxvffPMN77zzDp9++imPPfZYWJ+jTbd4j2fz5s1ccskljBkzhiuvvJKSkpLQba+99hoTJ07kggsuaHAVrnCbMGECK1asAGD58uVcffXVods2btzIxIkTGTVqFBMnTgytALZ06VJmz57NtGnTuOKKK5otttraWr799lv+8Y9/8NZbbwGwevVqJk2axMyZMznvvPNYsGBB6NtgVlYWjzzyCOPHj2f9+vXNFledxrx3kyZNYuvWraHjfvazn7Ft27ZmjXP16tX1WuJ33303S5cuBWDgwIE8+uijjB49muHDh0e0dXeiOFtaQ5+9huJbsWIF5557LhdffDH33HNPs/d8lJSUkJycjNVqBSAlJYWMjIwGzy+XXnop9957b4udX1atWoXVauX6668HwGg08uijj7JkyRKcTid/+MMfGD58OMOHD+f555/nueeeo6SkhMsuu4zJkyc3a2wmk4k5c+awaNGiY27Ly8tjypQpDB8+nClTppCfn09VVRUDBw4MnWdcLhdnnnkmfr+/WeME6NChA3//+9954YUXgnu6qyp//OMfGTt2LMOHD+ff//536Ni///3vDB8+nBEjRvD//t//O+Hjhi3x1tbWMmXKlNAJ5MMPPwQgNzeXYcOGcccdd3D++edzxRVXtMi3KgC32x3qZp45cyZ+v5977rmHl19+ma+++orrr7++3jdAl8vFihUr+Otf/8r8+fNbJMYrr7ySN998E4/Hw/bt2xk6dGjott69e/PRRx+xevVqfve73/Hggw+Gbvvuu+947rnneP/995sttg8//JDx48fTq1cvkpKS2Lx5MwCbNm3ikUceYe3atRw4cCAUg9PppH///nz++edccMEFzRZXnca8dzfccAOvvvoqAHv37sXr9TJgQGTXEk9JSWHVqlXceOON/OMf/4hoLNGioc/e8Xg8HhYsWMAbb7zBxx9/3CItqXHjxlFYWMjQoUO56667WLNmTVSdX3bu3MngwYPrXRcfH0+nTp14+eWXyc3NZdWqVaxdu5Zrr72WW2+9lfT0dN5//30++OCDZo0N4KabbuL111+nqqqq3vV3330306dPZ+3atVxzzTUsXLiQhIQEBgwYwJo1awD4+OOPGTduHGazudnjBOjWrRuapnHo0CFeeeUV4uPj+eKLL/jiiy9YvHgxOTk5fPrpp3z44Yd89tlnfP3119x5550nfMyw7cdrs9lYsmQJ8fHxHD58mIsuuohLLrkEgH379vHiiy/y1FNPMWfOHN57770WGYur6zKos2PHDnbu3MnUqVMB0DSNjh07hm6/6qqrABgxYgQ1NTVUVlaSmJjYrDEOGDCAvLw8li9fzsSJE+vdVl1dzbx589i/fz+KotT7hnfhhReSlNTw1oTh8OabbzJv3jzgxyQ3ceJEhgwZUm9zjHXr1nH55ZdjNBqZMmVKs8Z0tMa8d1OnTuXxxx/noYceYsmSJcyYMaPF4m3IZZddBsDgwYOb9YtUa9LQZ+94du/eTdeuXet9JhcvXtys8cXGxoa6mVevXs2NN97Ib37zm6g5v+i6ftxd33RdZ+3atdx4442YTMHTf3OfR44nPj6e6dOn8/zzz2O3/7j72nfffceSJUsAmD59Ovfffz8Q/Ay8/fbbjB49mjfffJObbrqpReOtWyJ55cqVbN++nXfffRcInmf279/Pl19+ycyZM3E4HMDJ39OwJV5d13nooYf4+uuvMRgMFBcXU1paCkDXrl0ZNGgQEDy55OXlhetpTzvGfv368emnnx739p9+UFtqu8JJkybxxz/+kQ8++IDy8vLQ9Y888gijRo1i6dKl5Obm1usCiomJadaYysvLWbVqFTt27EBRFDQtuH/yhAkTGnyfbDYbRqOxWeP6qdN97xwOB2PHjuWjjz7i7bff5ssvv2z2GE0mU73JGR6Pp97tdd2VRqOx2cfsT+RkcbaUhj57kyZNOm58p7NufDgZjUZGjRrFqFGjOPPMM3nhhRei5vxyxhln8N5779W7rrq6msLCQrp16xYVW7HedtttjB49mpkzZzZ4TF2ckyZN4oEHHqCiooItW7YwevTolgqTnJwcjEYjHTp0QNd1/vKXvzB+/Ph6x3z22Wen9Z6Grav59ddfp6ysjK+++oo1a9bQoUOH0C9G3YkFInty6d27N2VlZaHxR7/fz86dO0O3v/322wCsW7eO+Ph4EhISWiSu66+/nnvuuYczzzyz3vXV1dWhCUN13aMt5d1332X69Ols27aN7Oxstm/fTpcuXfjmm2/YtGkTOTk5aJrG22+/zfnnn9+isR2tMe/drFmzWLhwIUOGDGmRb/udO3dm165deL1eqqqq+Oqrr5r9ORsjWuJs6LMHHDe+Pn36kJubG6paqPs9bk579uxh3759oZ+zs7Pp27dv1JxfxowZg9vtZtmyZUBwsuMf/vAHZsyYwbhx4/jXv/4VOg9XVFQAEBcXR01NTbPF9FNJSUlcccUVoRYuwLBhw0KT6V5//fXQuSU2NpahQ4eycOFCfvazn7XYF/yysjIWLFjAzTffjKIojB8/npdeeinUg7Z3716cTifjxo1jyZIloVnhde9pQ8LW4q2uriY1NRWz2cyqVavIz88P10OHjcViYfHixSxcuJDq6mpUVWXevHmhpS4TExOZOHEiNTU1PP300y0WV1ZWVqhb7Wh33nkn8+bNY9GiRYwaNarF4oHgZKUFCxbUu27KlCn861//4txzz+WBBx5gx44dDB8+PNRVGgmNee8GDx5MXFzcCb9ph0MgEMBisdCpUyeuuOIKRowYQc+ePUO9P9Ei2uJs6LO3fPny48Znt9v561//ytVXX01KSgpDhgxp9hidTif33HMPVVVVGI1GevTowd///ndmz54dFecXRVFYsmQJd911F48//jiapjFhwgTuu+8+jEYje/fuZcSIEZhMJmbPns0tt9zC7Nmzueaaa+jYsWOLjPMCzJ8/nxdeeCH085///Gfmz5/PU089RWpqKs8880zotiuvvJLZs2c3e2x1c4MCgQBGo5Hp06dz++23A8Ev7Xl5eYwZMwZd10lJSWHp0qVcdNFFZGdnM3bsWMxmMxMnTuS+++5r8DmavGRkIBCgd+/ebNiwgenTp+P3+xk4cCDffvstb7zxBhDsq1+3bh0QrNmqra3lt7/9bVOeVkTI6tWrefrpp3nttdciHUqjFRcXM3nyZL777jsMhuab2J+dnc2dd97JypUrm+05wqG1xHkitbW1xMbGous6v/nNb+jRo0foZBkNLr30Uh5++GHOPvvsSIciokCTW7w7d+6ke/fupKSkNDi2UZd0AX75y1829SmFaLRly5bx8MMP88gjjzRr0v3Xv/7F888/H1ULAxxPa4nzZBYvXsyyZcvw+/0MGjSIuXPnRjokIRrUpBbv0b+048aNC2dcQgghRJskuxMJIYQQLei0+toKCgqYPHkyw4YN4/zzz+fZZ58FgjO4pk6dypAhQ5g6dSqVlZVAsCxg8uTJZGVlcffdd9d7rLfeeovhw4dz/vnnn3AQWgghhGhLTivxmkwmHn74YdavX8+nn37Kiy++yK5du3jyyScZM2YMmzZtYsyYMTz55JNAsIzo97///THrg5aXl3Pffffx3nvv8c0331BaWhq1JRZCCCFEOJ1W4k1PTw8tQxYXF0efPn0oLi7mo48+4rrrrgPguuuuCy0XGRMTwwUXXFCvjheCBck9e/YkNTUVCK7C9NNibyGEEKItavS0ztzcXLKzsxk6dCilpaWkp6cDweR86NChE963R48e7Nmzh9zcXAKBAB9++CEFBQWNDUUIIYRoNRpVTlRbW8usWbN49NFHiY+PP+37JyYm8sQTT3DjjTdiMBgYNmwYOTk5jQlFCCGEaFVOO/H6/X5mzZrFNddcE1oQPy0tjZKSEtLT0ykpKaFDhw4nfZxJkyYxadIkAP7zn/+0+Bq/QgghRCScVlezruvMnz+fPn361NvWatKkSaE1QZctWxbalehE6rqjKysrefHFF5k1a9bphCKEEEK0SqdVx7tu3TomTZpE//79Q6v+3HfffZxzzjnMmTOHgoICOnXqxOLFi0OLzw8cOJCamhr8fj8JCQm89dZb9OvXj5///OehDcjvueee0JZZQgghRFsmC2gIIYQQLaj5FqsVQgghxDEk8QohhBAtSBKvEEII0YIk8QohhBAtSBKvEEII0YIk8QrRxgwcOJAvv/wy0mEIIRrQqCUjhRDhNXDgQA4dOlRvBbcNGzaQkZERwaiEEM1BEq8QUeK///0vF154YaTDEEI0M+lqFiJKVVVVMX/+fPr27csZZ5zBww8/jKqqodsXL17MsGHD6NSpE+eddx6bN28O3Zadnc3w4cPp0qULc+fOxePxAMElWqdNm0bPnj3p2rUr06ZNo7CwsKVfmhDtmiReIaLUvHnzMJlMbNq0iVWrVrFy5UpefvllAN555x0ee+wxnnvuOfLz81m2bBnJycmh+7799tu8+eabbNmyhe3bt/Pqq68CoGkaM2bMIDs7m23btmGz2bj77rsj8vqEaK+kq1mIKDFz5szQGO+wYcNYtWoVubm52O12YmJiuO222/jPf/7D3Llzefnll7njjjsYMmQIENzj+mi/+MUvQuPDF198MdnZ2QAkJydz+eWXh4676667uOyyy1ri5QkhjpDEK0SUWLp0aWiMd+PGjXz++ef07ds3dLuu62RlZQFQWFhI9+7dG3ysjh07hv5tt9spKSkBwOVy8bvf/Y7PPvuMqqoqAGpqalBVVbbmFKKFSOIVIgplZWVhtVrZv38/JtOxv6ZZWVkcOHDgtB/36aefZs+ePXz++ed07NiRrVu3Mnr0aHRd9koRoqXIGK8QUSg9PZ2xY8fy+9//nurqajRN48CBA6xZswaAWbNm8fTTT7N582Z0XWf//v3k5eWd9HFra2ux2+0kJCRQUVHBn//85+Z+KUKIn5DEK0SUeu655/D7/Zx//vl069aNWbNmcfDgQQCmTp3KXXfdxU033USnTp2YOXMmFRUVJ33MefPm4Xa76dmzJxdddBEXXXRRc78MIcRPyH68QgghRAuSFq8QQgjRgiTxCiGEEC1IEq8QQgjRgiTxCiGEEC1IEq8QQgjRgiTxCiGEEC1IEq8QQgjRgiTxCiGEEC1IEq8QQgjRgv4/juMDUKfFXM8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 504x180 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "# ==============================================================================\n",
    "fig, ax = plt.subplots(figsize=(7, 2.5))\n",
    "data_test['yprecip'].plot(ax=ax, label='test')\n",
    "predictions_backtesting_ip['pred'].plot(ax=ax, label='prediction')\n",
    "ax.fill_between(\n",
    "    predictions_backtesting_ip.index,\n",
    "    predictions_backtesting_ip['lower_bound'],\n",
    "    predictions_backtesting_ip['upper_bound'],\n",
    "    color = 'green',\n",
    "    alpha = 0.2\n",
    ")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdc384e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e5575f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d76cc50e",
   "metadata": {},
   "source": [
    " # Importancia de los predictores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86d60e83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lag_1</td>\n",
       "      <td>0.271942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lag_2</td>\n",
       "      <td>0.024091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lag_3</td>\n",
       "      <td>0.039964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lag_4</td>\n",
       "      <td>0.230606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lag_5</td>\n",
       "      <td>0.100504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lag_6</td>\n",
       "      <td>0.102440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>lag_7</td>\n",
       "      <td>0.074699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lag_8</td>\n",
       "      <td>0.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lag_9</td>\n",
       "      <td>0.016926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lag_10</td>\n",
       "      <td>0.073828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature  importance\n",
       "0   lag_1    0.271942\n",
       "1   lag_2    0.024091\n",
       "2   lag_3    0.039964\n",
       "3   lag_4    0.230606\n",
       "4   lag_5    0.100504\n",
       "5   lag_6    0.102440\n",
       "6   lag_7    0.074699\n",
       "7   lag_8    0.065000\n",
       "8   lag_9    0.016926\n",
       "9  lag_10    0.073828"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.get_feature_importances()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d09641b",
   "metadata": {},
   "source": [
    "Tarea: Leer Recursive autoregressive forecasting with custom predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcbc48c",
   "metadata": {},
   "source": [
    "# Direct multi-step forecasting(ForecasterAutoregDirect)\n",
    "\n",
    "Las clases ForecasterAutoreg y ForecasterAutoregCustom siguen una estrategia de predicción recursiva en la que cada nueva predicción se basa en la anterior. Una alternativa es entrenar un modelo para cada uno de los pasos a predecir. Esta estrategia, comúnmente conocida como pronóstico directo de varios pasos(one-shot), es computacionalmente más costosa que la recursiva, ya que requiere entrenar varios modelos. Sin embargo, en algunos escenarios, logra mejores resultados. Este tipo de modelos se pueden obtener con la clase ForecasterAutoregDirect y pueden incluir una o varias variables exógenas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a3f6859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================= \n",
       "ForecasterAutoregDirect \n",
       "======================= \n",
       "Regressor: DecisionTreeRegressor(max_depth=6) \n",
       "Lags: [ 1  2  3  4  5  6  7  8  9 10] \n",
       "Transformer for y: StandardScaler() \n",
       "Transformer for exog: None \n",
       "Weight function included: False \n",
       "Window size: 10 \n",
       "Maximum steps predicted: 12 \n",
       "Exogenous included: False \n",
       "Type of exogenous variable: None \n",
       "Exogenous variables names: None \n",
       "Training range: None \n",
       "Training index type: None \n",
       "Training index frequency: None \n",
       "Regressor parameters: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 6, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'} \n",
       "fit_kwargs: {} \n",
       "Creation date: 2023-09-23 16:07:58 \n",
       "Last fit date: None \n",
       "Skforecast version: 0.8.0 \n",
       "Python version: 3.8.8 \n",
       "Forecaster id: None "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressor = DecisionTreeRegressor(max_depth=6)\n",
    "                \n",
    "\n",
    "forecaster = ForecasterAutoregDirect(\n",
    "                regressor = regressor,\n",
    "                lags      = 10,\n",
    "                steps     =12,\n",
    "                transformer_y = StandardScaler()\n",
    "             )\n",
    "\n",
    "forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8a70b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of models compared: 40.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "lags grid:   0%|          | 0/4 [00:00<?, ?it/s]\n",
      "params grid:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  10%|█         | 1/10 [00:00<00:01,  4.74it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  20%|██        | 2/10 [00:00<00:01,  4.71it/s]\u001b[A\n",
      "params grid:  30%|███       | 3/10 [00:00<00:01,  4.81it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  40%|████      | 4/10 [00:00<00:01,  4.83it/s]\u001b[A\n",
      "params grid:  50%|█████     | 5/10 [00:01<00:01,  4.85it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  60%|██████    | 6/10 [00:01<00:00,  4.84it/s]\u001b[A\n",
      "params grid:  70%|███████   | 7/10 [00:01<00:00,  4.87it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  80%|████████  | 8/10 [00:01<00:00,  4.84it/s]\u001b[A\n",
      "params grid:  90%|█████████ | 9/10 [00:01<00:00,  4.86it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n",
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid: 100%|██████████| 10/10 [00:02<00:00,  4.85it/s]\u001b[A\n",
      "lags grid:  25%|██▌       | 1/4 [00:02<00:06,  2.07s/it]    \u001b[A\n",
      "params grid:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  10%|█         | 1/10 [00:00<00:01,  4.73it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  20%|██        | 2/10 [00:00<00:01,  4.70it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  30%|███       | 3/10 [00:00<00:01,  4.69it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  40%|████      | 4/10 [00:00<00:01,  4.69it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  50%|█████     | 5/10 [00:01<00:01,  4.66it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  60%|██████    | 6/10 [00:01<00:00,  4.62it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  70%|███████   | 7/10 [00:01<00:00,  4.59it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  80%|████████  | 8/10 [00:01<00:00,  4.57it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  90%|█████████ | 9/10 [00:01<00:00,  4.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid: 100%|██████████| 10/10 [00:02<00:00,  4.54it/s]\u001b[A\n",
      "lags grid:  50%|█████     | 2/4 [00:04<00:04,  2.13s/it]    \u001b[A\n",
      "params grid:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  10%|█         | 1/10 [00:00<00:02,  4.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  20%|██        | 2/10 [00:00<00:01,  4.49it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  30%|███       | 3/10 [00:00<00:01,  4.51it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  40%|████      | 4/10 [00:00<00:01,  4.56it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  50%|█████     | 5/10 [00:01<00:01,  4.55it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  60%|██████    | 6/10 [00:01<00:00,  4.42it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  70%|███████   | 7/10 [00:01<00:00,  4.40it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  80%|████████  | 8/10 [00:01<00:00,  4.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  90%|█████████ | 9/10 [00:02<00:00,  4.45it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid: 100%|██████████| 10/10 [00:02<00:00,  4.45it/s]\u001b[A\n",
      "lags grid:  75%|███████▌  | 3/4 [00:06<00:02,  2.18s/it]    \u001b[A\n",
      "params grid:   0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  10%|█         | 1/10 [00:00<00:02,  4.48it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  20%|██        | 2/10 [00:00<00:01,  4.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  30%|███       | 3/10 [00:00<00:01,  4.41it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  40%|████      | 4/10 [00:00<00:01,  4.42it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  50%|█████     | 5/10 [00:01<00:01,  4.24it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  60%|██████    | 6/10 [00:01<00:00,  4.14it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  70%|███████   | 7/10 [00:01<00:00,  4.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  80%|████████  | 8/10 [00:01<00:00,  4.21it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid:  90%|█████████ | 9/10 [00:02<00:00,  4.10it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 60\n",
      "Number of observations used for backtesting: 60\n",
      "    Number of folds: 5\n",
      "    Number of steps per fold: 12\n",
      "    Number of steps to exclude from the end of each train set before test (gap): 0\n",
      "\n",
      "Fold: 0\n",
      "    Training:   2009-01-01 00:00:00 -- 2013-12-01 00:00:00  (n=60)\n",
      "    Validation: 2014-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=12)\n",
      "Fold: 1\n",
      "    Training:   2009-01-01 00:00:00 -- 2014-12-01 00:00:00  (n=72)\n",
      "    Validation: 2015-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=12)\n",
      "Fold: 2\n",
      "    Training:   2009-01-01 00:00:00 -- 2015-12-01 00:00:00  (n=84)\n",
      "    Validation: 2016-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=12)\n",
      "Fold: 3\n",
      "    Training:   2009-01-01 00:00:00 -- 2016-12-01 00:00:00  (n=96)\n",
      "    Validation: 2017-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=12)\n",
      "Fold: 4\n",
      "    Training:   2009-01-01 00:00:00 -- 2017-12-01 00:00:00  (n=108)\n",
      "    Validation: 2018-01-01 00:00:00 -- 2018-12-01 00:00:00  (n=12)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "params grid: 100%|██████████| 10/10 [00:02<00:00,  4.07it/s]\u001b[A\n",
      "lags grid: 100%|██████████| 4/4 [00:08<00:00,  2.22s/it]    \u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`Forecaster` refitted using the best-found lags and parameters, and the whole data set: \n",
      "  Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
      "  Parameters: {'max_depth': 3}\n",
      "  Backtesting metric: 1.786268737976498\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Grid search\n",
    "# ==============================================================================\n",
    "from skforecast.exceptions import LongTrainingWarning\n",
    "warnings.simplefilter('ignore', category=LongTrainingWarning)\n",
    "\n",
    "forecaster_direct_multi_step = ForecasterAutoregDirect(\n",
    "                regressor = regressor,\n",
    "                lags      = 10,\n",
    "                steps     =12,\n",
    "                transformer_y = StandardScaler()\n",
    "             )\n",
    "\n",
    "# Lags used as predictors\n",
    "lags_grid = [3,10, 12,20]\n",
    "\n",
    "# Regressor's hyperparameters\n",
    "param_grid = { 'max_depth': [1,2,3,4, 5,6,7,8,9, 10]}\n",
    "\n",
    "results_grid = grid_search_forecaster(\n",
    "                        forecaster         = forecaster_direct_multi_step,\n",
    "                        y                  = data_train['yprecip'],\n",
    "                        param_grid         = param_grid,\n",
    "                        lags_grid          = lags_grid,\n",
    "                        steps              = steps,\n",
    "                        refit              = True,\n",
    "                        metric             = 'mean_squared_error',\n",
    "                        initial_train_size = int(len(data_train)*0.5),\n",
    "                        fixed_train_size   = False,\n",
    "                        return_best        = True,\n",
    "                        verbose            = True\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e9883f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lags</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_squared_error</th>\n",
       "      <th>max_depth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>{'max_depth': 3}</td>\n",
       "      <td>1.786269</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>{'max_depth': 1}</td>\n",
       "      <td>1.842253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]</td>\n",
       "      <td>{'max_depth': 2}</td>\n",
       "      <td>1.896124</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 1}</td>\n",
       "      <td>2.117135</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n",
       "      <td>{'max_depth': 5}</td>\n",
       "      <td>2.121026</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       lags            params  \\\n",
       "22  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]  {'max_depth': 3}   \n",
       "20  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]  {'max_depth': 1}   \n",
       "21  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]  {'max_depth': 2}   \n",
       "10          [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  {'max_depth': 1}   \n",
       "14          [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  {'max_depth': 5}   \n",
       "\n",
       "    mean_squared_error  max_depth  \n",
       "22            1.786269          3  \n",
       "20            1.842253          1  \n",
       "21            1.896124          2  \n",
       "10            2.117135          1  \n",
       "14            2.121026          5  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search results\n",
    "# ==============================================================================\n",
    "results_grid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c4d637d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x180 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predictions\n",
    "# ==============================================================================\n",
    "predictions = forecaster_direct_multi_step.predict()\n",
    "\n",
    "# Gráfico\n",
    "# ==============================================================================\n",
    "fig, ax = plt.subplots(figsize=(7, 2.5))\n",
    "data_train['yprecip'].plot(ax=ax, label='train')\n",
    "data_test['yprecip'].plot(ax=ax, label='test')\n",
    "predictions.plot(ax=ax, label='predictions')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc613dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error\n",
    "# ==============================================================================\n",
    "error_mse = mean_squared_error(y_true = data_test['yprecip'], y_pred = predictions)\n",
    "print(f\"Test error (mse) {error_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "313a510d",
   "metadata": {},
   "source": [
    "Note que ahora el error es menor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "76ee92ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================= \n",
       "ForecasterAutoregDirect \n",
       "======================= \n",
       "Regressor: DecisionTreeRegressor(max_depth=3) \n",
       "Lags: [ 1  2  3  4  5  6  7  8  9 10 11 12] \n",
       "Transformer for y: StandardScaler() \n",
       "Transformer for exog: None \n",
       "Weight function included: False \n",
       "Window size: 12 \n",
       "Maximum steps predicted: 12 \n",
       "Exogenous included: False \n",
       "Type of exogenous variable: None \n",
       "Exogenous variables names: None \n",
       "Training range: None \n",
       "Training index type: None \n",
       "Training index frequency: None \n",
       "Regressor parameters: {'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': 3, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': None, 'splitter': 'best'} \n",
       "fit_kwargs: {} \n",
       "Creation date: 2023-09-23 16:09:15 \n",
       "Last fit date: None \n",
       "Skforecast version: 0.8.0 \n",
       "Python version: 3.8.8 \n",
       "Forecaster id: None "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train forecaster_direct_multi_step with the best hyperparameters\n",
    "# ==============================================================================\n",
    "regressor_direct_multi_step = DecisionTreeRegressor(max_depth=3)\n",
    "                \n",
    "\n",
    "forecaster_direct_multi_step = ForecasterAutoregDirect(\n",
    "                regressor = regressor_direct_multi_step,\n",
    "                lags      = 12,\n",
    "                steps     =12,\n",
    "                transformer_y = StandardScaler()\n",
    "             )\n",
    "\n",
    "forecaster_direct_multi_step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ed4840",
   "metadata": {},
   "source": [
    "## Pronósticos con Intervalos de predicción  con forecaster_direct_multi_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea7a7e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>lower_bound</th>\n",
       "      <th>upper_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>3.801756</td>\n",
       "      <td>-0.658948</td>\n",
       "      <td>6.119355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-01</th>\n",
       "      <td>3.723574</td>\n",
       "      <td>1.416129</td>\n",
       "      <td>6.119355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-01</th>\n",
       "      <td>3.758574</td>\n",
       "      <td>1.416129</td>\n",
       "      <td>6.119355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-01</th>\n",
       "      <td>7.993482</td>\n",
       "      <td>5.680050</td>\n",
       "      <td>10.233168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-01</th>\n",
       "      <td>8.325660</td>\n",
       "      <td>6.012228</td>\n",
       "      <td>10.615830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-01</th>\n",
       "      <td>6.709168</td>\n",
       "      <td>4.077419</td>\n",
       "      <td>9.098962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-01</th>\n",
       "      <td>6.735966</td>\n",
       "      <td>4.422534</td>\n",
       "      <td>9.125760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01</th>\n",
       "      <td>5.403447</td>\n",
       "      <td>3.117195</td>\n",
       "      <td>7.711780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-01</th>\n",
       "      <td>6.664500</td>\n",
       "      <td>4.378248</td>\n",
       "      <td>8.972834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-01</th>\n",
       "      <td>6.690591</td>\n",
       "      <td>4.077419</td>\n",
       "      <td>8.998925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-11-01</th>\n",
       "      <td>6.678765</td>\n",
       "      <td>4.077419</td>\n",
       "      <td>8.987098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-01</th>\n",
       "      <td>3.466321</td>\n",
       "      <td>0.864976</td>\n",
       "      <td>5.474194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                pred  lower_bound  upper_bound\n",
       "2019-01-01  3.801756    -0.658948     6.119355\n",
       "2019-02-01  3.723574     1.416129     6.119355\n",
       "2019-03-01  3.758574     1.416129     6.119355\n",
       "2019-04-01  7.993482     5.680050    10.233168\n",
       "2019-05-01  8.325660     6.012228    10.615830\n",
       "2019-06-01  6.709168     4.077419     9.098962\n",
       "2019-07-01  6.735966     4.422534     9.125760\n",
       "2019-08-01  5.403447     3.117195     7.711780\n",
       "2019-09-01  6.664500     4.378248     8.972834\n",
       "2019-10-01  6.690591     4.077419     8.998925\n",
       "2019-11-01  6.678765     4.077419     8.987098\n",
       "2019-12-01  3.466321     0.864976     5.474194"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps=12\n",
    "forecaster_direct_multi_step.fit(y=data_train['yprecip'])\n",
    "\n",
    "predictions_direct_multi_step = forecaster_direct_multi_step.predict_interval(\n",
    "                    steps    = steps,\n",
    "                    interval = [0.25, 99.75],\n",
    "                    n_boot   = 500\n",
    "              )\n",
    "\n",
    "predictions_direct_multi_step.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fb9fca6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error (mse): 0.6763991770837832\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x180 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prediction error\n",
    "# ==============================================================================\n",
    "error_mse_direct_multi_step = mean_squared_error(\n",
    "                y_true = data_test['yprecip'],\n",
    "                y_pred = predictions_direct_multi_step.iloc[:, 0]\n",
    "            )\n",
    "\n",
    "print(f\"Test error (mse): {error_mse_direct_multi_step}\")\n",
    "\n",
    "# Plot\n",
    "# ==============================================================================\n",
    "fig, ax = plt.subplots(figsize=(7, 2.5))\n",
    "data_test['yprecip'].plot(ax=ax, label='test')\n",
    "predictions_direct_multi_step['pred'].plot(ax=ax, label='prediction')\n",
    "ax.fill_between(\n",
    "    predictions_direct_multi_step.index,\n",
    "    predictions_direct_multi_step['lower_bound'],\n",
    "    predictions_direct_multi_step['upper_bound'],\n",
    "    color = 'green',\n",
    "    alpha = 0.2\n",
    ")\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99963b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
